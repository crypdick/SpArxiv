old_file,abstract
1801_06545_ms.tex," Telescopes are much more expensive than astronomers, so it is essential to minimize required sample sizes by using the most data-efficient statistical methods possible. However, the most commonly used model-independent techniques for finding the relationship between two variables in astronomy are flawed. In the worst case they can lead without warning to subtly yet catastrophically wrong results, and even in the best case they require more data than necessary. Unfortunately, there is no single best technique for nonparametric regression. Instead, we provide a guide for how astronomers can choose the best method for their specific problem and provide a python library with both wrappers for the most useful existing algorithms and implementations of two new algorithms developed here. "
1801_00696_main.tex," In this paper we consider pairs of interacting electrons moving in a simple quantum wire, namely the half-line $R_+$ . In particular, we extend the results obtained in KernerElectronPairs by allowing for contact interactions of the Lieb-Liniger type between the two electrons constituting the pair. We construct the associated Hamiltonian rigorously and study its spectral properties. We then investigate Bose-Einstein condensation of pairs and prove, as a main result, the existence of condensation whenever the Hamiltonian has a non-trivial discrete spectrum. Most importantly, condensation is proved for very weak and very strong contact interactions. "
1801_03764_V4.tex," We study analytically the polarization behaviour of directional couplers composed of birefringent waveguides, showing that they can induce polarization transformations that depend on the specific input-output path considered. On the basis of this study, we propose and demonstrate experimentally, by femtosecond laser writing, directional couplers that are free from this problem and also yield a polarization independent power-splitting ratio. More in detail, we devise two different approaches to realize such devices: the first one is based on local birefringence engineering, while the second one exploits ultra-low birefringence waveguides obtained by thermal annealing. "
1801_05015_axiomaticinfotherm2.tex," 	We present an axiomatic framework for thermodynamics that incorporates 	information as a fundamental concept. The axioms describe both ordinary 	thermodynamic processes and those in which information is acquired, used 	and erased, as in the operation of Maxwell's demon. 	This system, similar to previous axiomatic systems for thermodynamics, supports 	the construction of conserved quantities and an entropy function 	governing state changes. Here, however, the entropy exhibits 	both information and thermodynamic aspects. 	Although our axioms are not based upon probabilistic concepts, 	a natural and highly useful concept of probability 	emerges from the entropy function itself.  	Our abstract system has many models, including both classical 	and quantum examples. "
1801_00058_Galindro_Torres-rv.tex," We propose a simple mathematical model for unemployment. Despite its simpleness, we claim that the model is more realistic and useful than recent models available in the literature. A case study with real data from Portugal supports our claim. An optimal control problem is formulated and solved, which provides some non-trivial and interesting conclusions. "
1801_09397_asymmetric_manuscript.tex," % \boldmath In this paper we show how to break the angular symmetry of electromagnetic response of thin absorbers without breaking reciprocity. Based on our recent results on multichannel metasurfaces, we propose a new concept of asymmetric absorbers in which the absorption coefficient for waves impinging from a given oblique angle is extraordinarily different from that for waves incident from the oppositely tilted direction. The proposed asymmetric structure realizes controllable reflectance (from 0 to 0.99) for waves incident from one direction, exhibiting total absorption when the sign of the incidence angle is reversed. We provide a theoretical and numerical analysis for the asymmetric absorber, including design and numerical validation of its performance. "
1801_10549_CuSb2O6_ArXiv_v1.tex," Raman spectroscopy experiments on single crystals of CuSb $_2$ O $_6$ and CoSb $_2$ O $_6$ quasi-one-dimensional antiferromagnets with trirutile crystal structure were performed, with a focus on the first material. The observed Raman-active phonon modes and previously reported infrared-active modes were identified with the aid of {\it ab} -initio lattice dynamics calculations. The structural transition between monoclinic $\beta$ -CuSb $_2$ O $_6$ and tetragonal $\alpha$ -CuSb $_2$ O $_6$ phases at $T_s=400$ K is manifested in our spectra by a ``repulsion'' of two accidentally quasi-degenerate symmetric modes below $T_s$ , caused by a phonon mixing effect that is only operative in the monoclinic $\beta$ -CuSb $_2$ O $_6$ phase due to symmetry restrictions. Also, two specific phonons, associated with CuO $_6$ octahedra rotation and with a Jahn-Teller elongation mode, soften and broaden appreciably as $T \rightarrow T_s$ . A crossover from a displacive to an order-disorder transition at $T_s$ is inferred. "
1801_08428_Discrete_PMQ_ARX.tex," We propose a natural discretisation scheme for classical projective minimal surfaces. We follow the classical geometric characterisation and classification of projective minimal surfaces and introduce at each step canonical discrete models of the associated geometric notions and objects. Thus, we introduce discrete analogues of classical Lie quadrics and their envelopes and classify discrete projective minimal surfaces according to the cardinality of the class of envelopes. This leads to discrete versions of Godeaux-Rozet, Demoulin and Tzitz \'eica surfaces. The latter class of surfaces requires the introduction of certain discrete line congruences which may also be employed in the classification of discrete projective minimal surfaces. The classification scheme is based on the notion of discrete surfaces which are in asymptotic correspondence. In this context, we set down a discrete analogue of a classical theorem which states that an envelope (of the Lie quadrics) of a surface is in asymptotic correspondence with the surface if and only if the surface is either projective minimal or a Q surface. Accordingly, we present a geometric definition of discrete Q surfaces and their relatives, namely discrete counterparts of classical semi-Q, complex, doubly Q and doubly complex surfaces. "
1801_09449_TernaryNet_arxiv.tex," Deep convolutional neural networks (DCNN) are currently ubiquitous in medical imaging. While their versatility and high quality results for common image analysis tasks including segmentation, localisation and prediction is astonishing, the large representational power comes at the cost of highly demanding computational effort. This limits their practical applications for image guided interventions and diagnostic (point-of-care) support using mobile devices without graphics processing units (GPU). We propose a new scheme that approximates both trainable weights and neural activations in deep networks by ternary values and tackles the open question of backpropagation when dealing with non-differentiable functions. Our solution enables the removal of the expensive floating-point matrix multiplications throughout any convolutional neural network and replaces them by energy and time preserving binary operators and population counts. Our approach, which is demonstrated using a fully-convolutional network (FCN) for CT pancreas segmentation leads to more than 10-fold reduced memory requirements and we provide a concept for sub-second inference without GPUs. Our ternary approximation obtains high accuracies (without any post-processing) with a Dice overlap of 71.0 \% that are statistically equivalent to using networks with high-precision weights and activations. We further demonstrate the significant improvements reached in comparison to binary quantisation and without our proposed ternary hyperbolic tangent continuation. We present a key enabling technique for highly efficient DCNN inference without GPUs that will help to bring the advances of deep learning to practical clinical applications. It has also great promise for improving accuracies in large-scale medical data retrieval.  %  Deep Learning \and Pancreas \and Segmentation \and Sparsity \and Model compression \and Hamming distance "
1801_06369_main.tex," In this contribution, we present the results of the application of a parameter space reduction methodology based on active subspaces property to the hull hydrodynamic design problem. In the framework of such typical naval architecture problem, several parametric deformations of an initial hull shape are considered to assess the influence of the shape parameters considered on the hull total drag. The hull resistance, which is the performance parameter associated with each parametric hull, is typically computed by means of numerical simulations of the hydrodynamic flow past the ship. Such problem is extremely relevant at the preliminary stages of the ship design, when several flow simulations are typically carried out by the engineers to establish a certain sensibility on the total drag dependence on the hull geometrical parameters considered and on other physical parameters. Given the high number of geometric and physical parameters involved –which might result in a high number of time consuming hydrodynamic simulations– assessing whether the parameters space can be reduced would lead to considerable computational cost reduction at the design stage. Thus, the main idea of this work is to employ the active subspaces to identify possible lower dimensional structures in the parameter space, or to verify the parameter distribution in the position of the control points. To this end, a fully automated procedure has been implemented to produce several small shape perturbations of an original hull CAD geometry which are then used to carry out high-fidelity flow simulations in different cruise conditions and collect data for the active subspaces analysis. To achieve full automation of the open source pipeline described, both the free form deformation methodology employed for the hull perturbations and the high fidelity solver based on unsteady potential flow theory, with fully nonlinear free surface treatment, are directly interfaced with CAD data structures and operate using IGES vendor-neutral file formats as input files. The computational cost of the fluid dynamic simulations is further reduced through the application of dynamic mode decomposition is to reconstruct the final, steady state total drag value given only few initial snapshots of the simulation. The active subspaces analysis is here applied to the geometry of the DTMB-5415 naval combatant hull, which is a common benchmark in ship hydrodynamics simulations, within the SISSA mathLab applied mathematics lab. The contribution will discuss several details of the implementation of the tools developed, as well as the results of their application to the target engineering problem. "
1801_06863_main.tex," %% Text of abstract Amidst widespread reports of digital influence operations during major elections, policymakers, scholars, and journalists have become increasingly interested in the political impact of social media `bots.' Most recently, platform companies like Facebook and Twitter have been summoned to testify about bots as part of investigations into digitally-enabled foreign manipulation during the 2016 US Presidential election. Facing mounting pressure from both the public and from legislators, these companies have been instructed to crack down on apparently malicious bot accounts. But as this article demonstrates, since the earliest writings on bots in the 1990s, there has been substantial confusion as to exactly what a `bot' is and what exactly a bot does. We argue that multiple forms of ambiguity are responsible for much of the complexity underlying contemporary bot-related policy, and that before successful policy interventions can be formulated, a more comprehensive understanding of bots --- especially how they are defined and measured --- will be needed. In this article, we provide a history and typology of different types of bots, provide clear guidelines to better categorize political automation and unpack the impact that it can have on contemporary technology policy, and outline the main challenges and ambiguities that will face both researchers and legislators concerned with bots in the future. "
1801_01215_NGC650.tex,"  With its bright and wide equatorial waist seen almost edge-on ( ``the butterfly body'' ) and the faint and broad bipolar extensions ( \emph{``the butterfly wings''} ), NGC \sc SHAPE is the archetypical example of bipolar planetary nebula (PN) with butterfly morphology. We present here deep high-resolution broad- and narrow-band optical images that expose the rich and intricate fine-structure of this bipolar PN, with % ``cometary'' knots and small-scale bubble-like features and collimated outflows.  A  spatio-kinematical model indicates that NGC \,650-1 has a broad central torus with an inclination angle of 75$\degr$ with respect to the line of sight, whereas that of the bipolar lobes, which are clearly seen in the position-velocity maps, is 85 $\degr$ . Large field of view deep images show, for first time, an arc-like diffuse envelope in low- and high-excitation emission lines located up to 180 \arcsec \ towards the East-Southeast of the central star, well outside the main nebula. This morphological component is confirmed by Spitzer MIPS and WISE infrared imaging, as well as by long-slit low- and high-dispersion optical spectroscopic observations. HST images of NGC \,650-1 obtained at two different epochs $\sim$ 14 yrs apart reveal the proper motion of the central star along this direction. We propose that this motion of the star through the interstellar medium compresses the remnant material of a slow Asymptotic Giant Branch wind, producing this bow-shock-like feature. "
1801_01081_Mult.tex," We present a novel set of reversible modular multipliers applicable to quantum computing, derived from three classical techniques: 1) traditional integer division, 2) Montgomery residue arithmetic~ Montgomery1985 , and 3) Barrett reduction~ Barrett1987 . Each multiplier computes an exact result for all binary input values, while maintaining the asymptotic resource complexity of a single (non-modular) integer multiplier. We additionally conduct an empirical resource analysis of our designs in order to determine the total gate count and circuit depth of each fully constructed circuit, with inputs as large as 2048 bits. Our comparative analysis considers both circuit implementations which allow for arbitrary (controlled) rotation gates, as well as those restricted to a typical fault-tolerant gate set. "
1801_05857_main.tex," The use of graphics processors (GPUs) is a promising approach to speed up model checking to such an extent that it becomes feasible to instantly verify software systems during development. \GPUexplore is an explicit-state model checker that runs all its computations on the GPU. Over the years it has been extended with various techniques, and the possibilities to further improve its performance have been continuously investigated. In this paper, we discuss how the hash table of the tool works, which is at the heart of its functionality. We propose an alteration of the hash table that in isolated experiments seems promising, and analyse its effect when integrated in the tool. Furthermore, we investigate the current scalability of \GPUexplore, by experimenting both with input models of varying sizes and running the tool on one of the latest GPUs of NVIDIA. "
1801_05991_paper.tex," To fathom the mechanism of high-temperature ( $T_{\rm c}$ ) superconductivity, the dynamical vertex approximation (D $\Gamma$ A) is evoked for the two-dimensional repulsive Hubbard model.  After showing that our results well reproduce the cuprate phase diagram with a reasonable $T_{\rm c}$ and dome structure, we keep track of the scattering processes that primarily affect $T_{\rm c}$ . We find that local particle-particle diagrams significantly screen the bare interaction, which in turn suppress the pairing interaction. Hence we identify such vertex corrections as one of the main oppressors of $T_{\rm c}$ .  This may provide a hint for boosting the pairing strength, and hence toward higher $T_{\rm c}$ . "
1801_09552_Pusgr_17.tex,"\small{In this papper, we give an introduction to basic concepts of automaton semigroups. While we must note that this paper does not contain new results, it is focused on extended introduction in the subject and detailed examples.}"
1801_07735.tex," The multipolar Hamiltonian of quantum electrodynamics (QED) is extensively employed in chemical and optical physics to treat rigorously the interaction of electromagnetic fields with matter. It is also widely used to evaluate intermolecular interactions. The multipolar version of the Hamiltonian is commonly obtained by carrying out a unitary transformation of the Coulomb gauge Hamiltonian that goes by the name of Power-Zienau-Woolley (PZW). Not only does the formulation provide excellent agreement with experiment, and versatility in its predictive ability, but also superior physical insight. Recently, the foundations and validity of the PZW Hamiltonian have been questioned, raising a concern over issues of gauge transformation and invariance, and whether observable quantities obtained from unitarily equivalent Hamiltonians are identical. Here, an in-depth analysis of theoretical foundations clarifies the issues and enables misconceptions to be identified. Claims of non-physicality are refuted: the PZW transformation and ensuing Hamiltonian are shown to rest on solid physical principles and secure theoretical ground. "
1801_03895_ISIT18.tex," Index coding achieves bandwidth savings by jointly encoding the messages demanded by all the clients in a broadcast channel. The encoding is performed in such a way that each client can retrieve its demanded message from its side information and the broadcast codeword. In general, in order to decode its demanded message symbol, a receiver may have to observe the entire transmitted codeword. Querying or downloading the codeword symbols might involve costs to a client -- such as network utilization costs and storage requirements for the queried symbols to perform decoding. In traditional index coding solutions, this client aware perspective is not considered during code design. As a result, for these codes, the number of codeword symbols queried by a client per decoded message symbol, which we refer to as `locality', could be large. In this paper, considering locality as a cost parameter, we view index coding as a trade-off between the achievable broadcast rate (codeword length normalized by the message length) and locality, where the objective is to minimize the broadcast rate for a given value of locality and vice versa. We show that the smallest possible locality for any index coding problem is 1, and that the optimal index coding solution with locality 1 is the coding scheme based on fractional coloring of the interference graph. We propose index coding schemes with small locality by covering the side information graph using acyclic subgraphs and subgraphs with small minrank. We also show how locality can be accounted for in conventional partition multicast and cycle covering solutions to index coding. Finally, applying these new techniques, we characterize the locality-broadcast rate trade-off of the index coding problem whose side information graph is the directed 3-cycle. "
1801_06386_intro.tex," In this paper we study some consequences of the author's classification of graph manifolds by their profinite fundamental groups. In particular we study commensurability, the behaviour of knots, and relation to mapping classes. We prove that the exteriors of graph knots are distinguished among all 3-manifold groups by their profinite fundamental groups. We also prove a strong conjugacy separability result for certain mapping classes of surfaces. "
1801_07705_submit.tex," Reliable first-principles calculations of electrochemical processes require accurate prediction of the interfacial capacitance, a challenge for current computationally-efficient continuum solvation methodologies. We develop a model for the double layer of a metallic electrode that reproduces the features of the experimental capacitance of Ag(100) in a non-adsorbing, aqueous electrolyte, including a broad hump in the capacitance near the Potential of Zero Charge (PZC), and a dip in the capacitance under conditions of low ionic strength. Using this model, we identify the necessary characteristics of a solvation model suitable for first-principles electrochemistry of metal surfaces in non-adsorbing, aqueous electrolytes: dielectric and ionic nonlinearity, and a dielectric-only region at the interface. The dielectric nonlinearity, caused by the saturation of dipole rotational response in water, creates the capacitance hump, while ionic nonlinearity, caused by the compactness of the diffuse layer, generates the capacitance dip seen at low ionic strength. We show that none of the previously developed solvation models simultaneously meet all these criteria. We design the Nonlinear Electrochemical Soft-Sphere solvation model (NESS) which both captures the capacitance features observed experimentally, and serves as a general-purpose continuum solvation model. "
1801_10395_prssm_arxiv_paper.tex, 	 content/abstract 	 -5mm
1801_02766.tex, We give a purely scheme theoretic construction of the filtration by ramification groups of the Galois group of a covering. The valuation need not be discrete but the normalizations are required to be locally of complete intersection.
1801_06267_ms.tex," Mobile app development involves a unique set of challenges including device fragmentation and rapidly evolving platforms, making testing a difficult task. The design space for a comprehensive mobile testing strategy includes features, inputs, potential contextual app states, and large combinations of devices and underlying platforms. Therefore, automated testing is an essential activity of the development process. However, current state of the art of automated testing tools for mobile apps poses limitations that has driven a preference for manual testing in practice. As of today, there is no comprehensive automated solution for mobile testing that overcomes fundamental issues such as automated oracles, history awareness in test cases, or automated evolution of test cases. In this perspective paper we survey the current state of the art in terms of the frameworks, tools, and services available to developers to aid in mobile testing, highlighting present shortcomings. Next, we provide commentary on current key challenges that restrict the possibility of a comprehensive, effective, and practical automated testing solution. Finally, we offer our vision of a comprehensive mobile app testing framework, complete with research agenda, that is succinctly summarized along three principles: Continuous, Evolutionary and Large-scale (CEL). "
1801_09633_informativeness-actionability.tex,"\abstract{ Crisis responders are increasingly using social media, data and other digital sources of information to build a situational understanding of a crisis situation in order to design an effective response. However with the increased availability of such data, the challenge of identifying relevant information from it also increases. This paper presents a successful automatic approach to handling this problem. Messages are filtered for informativeness based on a definition of the concept drawn from prior research and crisis response experts. Informative messages are tagged for actionable data -- for example, people in need, threats to rescue efforts, changes in environment, and so on. In all, eight categories of actionability are identified. The two components -- informativeness and actionability classification -- are packaged together as an openly-available tool called Emina (Emergent Informativeness and Actionability). }"
1801_05466_sts.tex," We derive and study a significance test for determining if a panel of functional time series is separable. In the context of this paper, separability means that the covariance structure factors into the product of two functions, one depending only on time and the other depending only on the coordinates of the panel. Separability is a property which can dramatically improve computational efficiency by substantially reducing model complexity. It is especially useful for functional data as it implies that the functional principal components are the same for each member of the panel. However such an assumption must be verified before proceeding with further inference. Our approach is based on functional norm differences and provides a test with well controlled size and high power. We establish our procedure quite generally, allowing one to test separability of autocovariances as well. In addition to an asymptotic justification, our methodology is validated by a simulation study. It is applied to functional panels of particulate pollution and stock market data. "
1801_04514_arxiv.tex," We develop a framework for the general interpretation of the stochastic dynamical system near a limit cycle.  Such quasi-periodic dynamics are commonly found in a variety of nonequilibrium systems, including the spontaneous oscillations of hair cells in the inner ear.  We demonstrate quite generally that in the presence of noise, the phase of the limit cycle oscillator will diffuse while deviations in the directions locally orthogonal to that limit cycle will display the Lorentzian power spectrum of a damped oscillator. We identify two mechanisms by which these stochastic dynamics can acquire a complex frequency dependence, and discuss the deformation of the mean limit cycle as a function of temperature. The theoretical ideas are applied to data obtained from spontaneously oscillating hair cells of the amphibian sacculus. "
1801_07888_Dicke_SpinHalf.tex," The Dicke model is of fundamental importance in quantum mechanics for understanding the collective behaviour of atoms coupled to a single electromagnetic mode. In this paper, we demonstrate a Dicke-model simulation using cavity-assisted Raman transitions in a configuration using counter-propagating laser beams. The observations indicate that motional effects should be included to fully account for the results and these results are contrasted with the experiments using single-beam and co-propagating configurations. A theoretical description is given that accounts for the beam geometries used in the experiments and indicates the potential role of motional effects. In particular a model is given that highlights the influence of Doppler broadening on the observed thresholds. "
1801_08565_Rollercoaster.tex," 		A {\em rollercoaster} is a sequence of real numbers for which every maximal contiguous subsequence, that is increasing or decreasing, has length at least three. By translating this sequence to a set of points in the plane, a rollercoaster can be defined as a polygonal path for which every maximal sub-path, with positive- or negative-slope edges, has at least three points. Given a sequence of distinct real numbers, the rollercoaster problem asks for a maximum-length (not necessarily contiguous) subsequence that is a rollercoaster. It was conjectured that every sequence of $n$ distinct real numbers contains a rollercoaster of length at least $\lceil n/2\rceil$ for $n>7$ , while the best known lower bound is $\Omega(n/\log n)$ . In this paper we prove this conjecture. Our proof is constructive and implies a linear-time algorithm for computing a rollercoaster of this length. Extending the $O(n\log n)$ -time algorithm for computing a longest increasing subsequence, we show how to compute a maximum-length rollercoaster within the same time bound. A maximum-length rollercoaster in a permutation of $1,\dots,n\$ can be computed in $O(n \log \log n)$ time. 		 		 		The search for rollercoasters was motivated by orthogeodesic point-set embedding of caterpillars. A {\em caterpillar} is a tree such that deleting the leaves gives a path, called the {\em spine} . A {\em top-view caterpillar} is one of degree 4 such that the two leaves adjacent to each vertex lie on opposite sides of 		the spine. As an application of our result on rollercoasters, we are able to find a planar drawing of every $n$ -node top-view caterpillar on every set of $25{3}n$ points in the plane, such that each edge is an orthogonal path with one bend. This improves the previous best known upper bound on the number of required points, which is $O(n \log n)$ . We also show that such a drawing can be obtained in linear time, provided that the points are given in sorted order. 	"
1801_00958.tex," In this paper, we solve the problem of exponential stabilization for a class of cascade ODE-PDE system governed by a linear ordinary differential equation and a $1-d$ linearized Korteweg-de Vries equation (KdV) posed on a bounded interval. The control for the entire system acts on the left boundary with Dirichlet condition of the KdV equation whereas the KdV acts in the linear ODE by a Dirichlet connection. We use the so-called backstepping design in infinite dimension to convert the system under consideration into an exponentially stable cascade ODE-PDE system.Then, we use the invertibility of such design to achieve the exponential stability for the ODE-PDE cascade system under consideration by using Lyapunov analysis. "
1801_08387_minimal-model-on-degenerating-genus-2-surfaces-01-2018.tex," In the $(2,5)$ minimal model, the partition function for genus $g=2$ Riemann surfaces is expected to be given by a quintuplet of Siegel modular forms that extend the Rogers-Ramanujan functions on the torus. Their expansions around the $g=2$ boundary components of the moduli space are obtained in terms of standard modular forms. In the case where a handle of the $g=2$ surface is pinched, our method requires knowledge of the $2$ -point function of the fundamental lowest-weight vector in the non-vacuum representation of the Virasoro algebra, for which we derive a third order ODE. "
1801_07061_Adaptive_PNC_arXiv.tex," Physical layer network coding (PNC) has been studied to serve wireless network MIMO systems with much lower backhaul load than approaches such as Cloud Radio Access Network (Cloud-RAN) and coordinated multipoint (CoMP). In this paper, we present a design guideline of engineering-applicable PNC to fulfil the request of high user densities in 5G wireless RAN infrastructure. Unlike computer-and-forward and PNC schemes designed for two-way relay channels, the proposed PNC is designed for uplink of network MIMO systems. We show that the proposed design criterion guarantee that 1) the whole system operates over binary system; 2) each access point can choose singular PNC function to overcome all fade states; 3) the destination can unambiguously recover all source messages while the overall backhaul load remains at the lowest level regardless of which digital mapping is used. We develop a two-stage search algorithm to identify the optimum PNC mapping functions with a practical selection approach which greatly reduces the real-time computation complexity is presented with a small performance loss. Numerical results show that the proposed scheme achieves low bit error rate with reduced backhaul load. "
1801_06527_IAUS333_proceedings_HannahRoss.tex," The upcoming radio interferometer Square Kilometre Array is expected to directly detect the redshifted 21-cm signal from the Cosmic Dawn for the first time. In this era temperature fluctuations from X-ray heating of the neutral intergalactic medium can impact this signal dramatically. Previously, in Ross2017 , we presented the first large-volume, 244~ $h^{-1}$ Mpc=349 \,Mpc a side, fully numerical radiative transfer simulations of X-ray heating. This work is a follow-up where we now also consider QSO-like sources in addition to high mass X-ray binaries. Images of the two cases are clearly distinguishable at SKA1-LOW resolution and have RMS fluctuations above the expected noise. The inclusion of QSOs leads to a dramatic increase in non-Gaussianity of the signal, as measured by the skewness and kurtosis of the 21-cm signal. We conclude that this increased non-Gaussianity is a promising signature of early QSOs.  cosmology: theory --- radiative transfer --- reionization --- intergalactic medium --- large-scale structure of universe --- galaxies: formation --- QSOs %% add here a maximum of 10 keywords, to be taken form the file <Keywords.txt> "
1801_06743_Ce3-xCo9MgxVT_DP.tex," We report on the synthesis of single crystalline and polycrystalline samples of Ce $_{3-x}$ Mg $_x$ Co $_9$ solid solution ( $0\leq x \lesssim 1.4$ ) and characterization of their structural and magnetic properties. The crystal structure remains rhombohedral in the whole composition range and Mg partially replaces Ce in the 6 c site of the CeCo $_3$ structure. Ferromagnetism is induced by Mg substitutions starting as low as  $x=0.18$ and reaching a Curie temperature as high as $450$ \,K for $x=1.35$ . Measurements on single crystals with $x=1.34$ and $T_C=440$ \,K indicate an axial magnetic anisotropy with the anisotropy field of $6$ \,T and a magnetization of $6$ \, $\mu_B/$ f.u. at $300$ \,K. Coercicity is observed in the polycrystalline samples consistent with the observed axial magnetic anisotropy. Our discovery of ferromagnetism with large axial magnetic anisotropy induced by substituting a rare-earth element by Mg is a very promising result in the search of inexpensive permanent-magnet materials and suggests other non-magnetic phases, similar to CeCo$_3$ , may also conceal nearby ferromagnetic phases. "
1801_01450_qti_eka.tex," A fundamental problem in object recognition is the development of image representations that are invariant to common transformations such as translation, rotation, and small deformations. There are multiple hypotheses regarding the source of translation invariance in CNNs. One idea is that translation invariance is due to the increasing receptive field size of neurons in successive convolution layers. Another possibility is that invariance is due to the pooling operation. We develop a simple a tool, the translation-sensitivity map, which we use to visualize and quantify the translation-invariance of various architectures. We obtain the surprising result that architectural choices such as the number of pooling layers and the convolution filter size have only a secondary effect on the translation-invariance of a network. Our analysis identifies training data augmentation as the most important factor in obtaining translation-invariant representations of images using convolutional neural networks. "
1801_02800_arxiv-holevo-fidelity_isit18.tex," Holevo's just-as-good fidelity is a similarity measure for quantum states that has found several applications. One of its critical properties is that it obeys a data processing inequality: \ the measure does not decrease under the action of a quantum channel on the underlying states. In this paper, I prove a refinement of this data processing inequality that includes an additional term related to recoverability. That is, if the increase in the measure is small after the action of a partial trace, then one of the states can be nearly recovered by the Petz recovery channel, while the other state is perfectly recovered by the same channel. The refinement is given in terms of the trace distance of one of the states to its recovered version and also depends on the minimum eigenvalue of the other state. As such, the refinement is universal, in the sense that the recovery channel depends only on one of the states, and it is explicit, given by the Petz recovery channel. The appendix contains a generalization of the aforementioned result to arbitrary quantum channels. "
1801_00788_Hydro_CGM_v4.tex,"  Hydrostatic equilibrium (HSE), where the thermal pressure gradient  balances the force of gravity, is tested across a range of simulated  EAGLE haloes from Milky Way $L^*$ haloes ( $M_{200}12  \msolar$ ) to cluster scales. Clusters ( $M_{200}14  \msolar$ ) reproduce previous results with thermal pressure  responsible for $\sim 90\%$ of the support against gravity, but this  fraction drops for group-sized haloes ( $M_{200}13  \msolar$ ) and is even lower ( $40-70\%$ ) for $L^*$ haloes between  $0.1-0.3 R_{200}$ . Energy from feedback grows relative to the  binding energy of a halo toward lower mass resulting in greater  deviations from HSE. Tangential motions comprise the largest  deviation from HSE in $L^*$ haloes indicating that the hot  circumgalactic medium (CGM) has significant sub-centrifugal rotation  and angular momentum spin parameters $2-3\times$ higher than the  dark matter spin parameters. Thermal feedback can buoyantly rise to  the outer CGM of $M_{200}12 \msolar$ haloes, both moving  baryons beyond $R_{200}$ and feeding uncorrelated tangential  motions. The resulting hot halo density and rotation profiles show  promising agreement with X-ray observations of the inner Milky Way  halo, and we discuss future observational prospects to detect  spinning hot haloes around other galaxies. Acceleration and radial  streaming motions also comprise significant deviations from HSE,  especially net outward accelerations seen in $L^*$ and group haloes  indicating active feedback. Black hole feedback acts in a  preventative manner during the later growth of group haloes,  applying significant accelerations via shocks that do not feed  tangential motions. We argue that HSE is a poor assumption for the  CGM, especially in the inner regions, and rotating baryonic hot  haloes are a critical consideration for analytic models of the CGM.  %XXX  "
1801_04071_misawa.tex," We performed spectroscopic observations of the small-separation lensed quasar SDSS~J1001+5027, whose images have an angular separation $\!\!\prime\prime86$ , and placed constraints on the physical properties of gas clouds in the vicinity of the quasar (i.e., in the outflowing wind launched from the accretion disk). The two cylinders of sight to the two lensed images go through the same region of the outflowing wind and they become fully separated with no overlap at a very large distance from the source ( $\sim$ 330~pc). We discovered a clear difference in the profile of the C{4} broad absorption line (BAL) detected in the two lensed images in two observing epochs. Because the kinematic components in the BAL profile do not vary in concert, the observed variations cannot be reproduced by a simple change of ionization state. If the variability is due to gas motion around the background source (i.e., the continuum source), the corresponding rotational velocity is $v_{\rm rot}\geq 18,000$ ~ \kms, and their distance from the source is $r\leq 0.06$ ~pc assuming Keplerian motion. Among three Mg{2} and three C{4} NAL systems that we detected in the spectra, only the Mg{2} system at \zabs \ = 0.8716 shows a hint of variability in its Mg{1} profile on a rest-frame time scale of $\Delta t_{\rm  rest}$  $\leq$ 191~days and an obvious velocity shear between the sightlines whose physical separation is $\sim$ 7~kpc. We interpret this as the result of motion of a cosmologically intervening absorber, perhaps located in a foreground galaxy. "
1801_08230_main.tex," This paper describes an approach that combines generative adversarial networks (GANs) with interactive evolutionary computation (IEC). While GANs can be trained to produce lifelike images, they are normally sampled randomly from the learned distribution, providing limited control over the resulting output. On the other hand, interactive evolution has shown promise in creating various artifacts such as images, music and 3D objects, but traditionally relies on a hand-designed evolvable representation of the target domain. The main insight in this paper is that a GAN trained on a specific target domain can act as a compact and robust genotype-to-phenotype mapping (i.e. \ most produced phenotypes do resemble valid domain artifacts). Once such a GAN is trained, the latent vector given as input to the GAN's generator network can be put under evolutionary control, allowing controllable and high-quality image generation.  In this paper, we demonstrate the advantage of this novel approach through a user study in which participants were able to evolve images that strongly resemble specific target images. "
1801_08586_main.tex, abstract
1801_06172_cpfm_sentiment_fm.tex," %While existing machine learning-based methods have achieved great success for sentiment classification, they typically cannot explicitly capture sentiment-oriented word interaction, which causes poor results for fine-grained analysis at the snippet level (a phrase or sentence).  While existing machine learning models have achieved great success for sentiment classification, they typically do not explicitly capture sentiment-oriented word interaction, which can lead to poor results for fine-grained analysis at the snippet level (a phrase or sentence). Factorization Machine provides a possible approach to learning element-wise interaction for recommender systems, but they are not directly applicable to our task due to the inability to model contexts and word sequences. In this work, we develop two Position-aware Factorization Machines which consider word interaction, context and position information. Such information is jointly encoded in a set of sentiment-oriented word interaction vectors. Compared to traditional word embeddings, SWI vectors explicitly capture sentiment-oriented word interaction and simplify the parameter learning. Experimental results show that while they have comparable performance with state-of-the-art methods for document-level classification, they benefit the snippet/sentence-level sentiment analysis.  "
1801_09684_manuscript.tex," Machine learning is actively being explored for its potential to design, validate, and even hybridize with near-term quantum devices. Stochastic neural networks will play a central role in state tomography, due to their ability to model a quantum wavefunction. However, to be useful in real experiments such methods must be able to reconstruct general quantum mixed states. Here, we parameterize a density matrix based on a restricted Boltzmann machine that is capable of purifying an arbitrary state through auxiliary degrees of freedom embedded in the latent space of its hidden units. We implement the algorithm numerically and use it to perform tomography on some typical states of entangled photons, and achieve fidelities competitive with standard techniques. "
1801_03216_Counterexample.tex," The convex feasibility problem consists in finding a point in the intersection of a finite family of closed convex sets. When the intersection is empty, a best compromise is to search for a point that minimizes the sum of the squared distances to the sets. In 2001, de Pierro conjectured that the limit cycles generated by the  $\varepsilon$ -under-relaxed cyclic projection method converge when $\varepsilon\downarrow 0$ towards a least squares solution. While the conjecture has been confirmed under fairly general conditions, we show that the property is false in general by constructing a system of three compact convex sets in $\R^3$ for which the  $\varepsilon$ -under-relaxed cycles do not converge. "
1801_08841_main.tex,"   % State the problem, your approach and solution, and the main contributions of the paper. Include little if any background and motivation. Be factual but comprehensive. The material in the abstract should not be repeated later word for word in the paper.%   Reinforcement Learning (RL) is a research area that has blossomed tremendously in recent years and has shown remarkable potential in among others successfully playing computer games. However, there only exists a few game platforms that provide diversity in tasks and state-space needed to advance RL algorithms. The existing platforms offer RL access to Atari- and a few web-based games, but no platform fully expose access to Flash games. This is unfortunate because applying RL to Flash games have potential to push the research of RL algorithms.      This paper introduces the Flash Reinforcement Learning platform (FlashRL) which attempts to fill this gap by providing an environment for thousands of Flash games on a novel platform for Flash automation. It opens up easy experimentation with RL algorithms for Flash games, which has previously been challenging. The platform shows excellent performance with as little as 5 \% CPU utilization on consumer hardware. It shows promising results for novel reinforcement learning algorithms. "
1801_06861_sample-sigconf.tex," The demo will illustrate the features of a webGIS interface to support the rapid mapping activities after a natural disaster, with the goal of providing additional information from social media to the mapping operators. This demo shows the first results of the E2mC H2020 European project, where the goal is to extract precisely located information from available social media sources, providing accurate geolocating functionalities and, starting from posts searched in Twitter, extending the social media exploration to Flickr, YouTube, and Instagram. "
1801_04992_data.tex," In this article, the data notion is mathematically conceptualized as typed information based on the two concepts of information and computable functionality. A data type is defined as a pair of a set of distinguishable characters (an alphabet) and a set of operations (surjective, computable functions) that operate on this alphabet as domain and capture the intent of a parameterizable concept. Two different ways to construct new data types from existing ones are described: restriction and extension. They lead to two different partial orders on types in the sense of subtyping as formulated by Liskov and Wing. It is argued that the proposed data concept matches the concept of characteristics (Merkmale) of the automation industry. "
1801_07213_Supplementary.tex," % %Catastrophic events, though rare, do occur and when they occur, they have devastating effects. It is, therefore, of utmost importance to understand the complexity of the underlying dynamics and signatures of catastrophic events, such as market crashes. For deeper understanding, we choose the US and Japanese markets from 1985 onward, and study the evolution of the cross-correlation structures of stock return matrices and their eigenspectra over different short time-intervals or “epochs”. A slight non-linear distortion is applied to the correlation matrix computed for any epoch, leading to the {\it emerging spectrum} of eigenvalues. The statistical properties of the emerging spectrum display: (i) the shape of the emerging spectrum reflects the market instability, (ii) the smallest eigenvalue may be able to statistically distinguish the nature of a market turbulence or crisis -- internal instability or external shock, and (iii) the time-lagged smallest eigenvalue has a statistically significant correlation with the mean market cross-correlation. The smallest eigenvalue seems to indicate that the financial market has become more turbulent in a similar way as the mean does. Yet we show features of the smallest eigenvalue of the emerging spectrum that distinguish different types of market instabilities related to internal or external causes. Based on the paradigmatic character of financial time series for other complex systems, the capacity of the emerging spectrum to understand the nature of instability may be a new feature, which can be broadly applied. %"
1801_05573_main.tex," The Square Kilometre Array (SKA) Epoch of Reionisation and Cosmic Dawn (EoR/CD) experiments aim to explore the growth of structure and production of ionising radiation in the first billion years of the Universe. Here I describe the experiments planned for the future low-frequency components of the Observatory, and work underway to define, design and execute these programs. instrumentation: interferometers, surveys, early universe %% add here a maximum of 10 keywords, to be taken form the file <Keywords.txt> "
1801_01879_tn_surface_decode.tex," A quantum error correcting protocol can be substantially improved by taking into account features of the physical noise process. We present an efficient decoder for the surface code which can account for general noise features, including coherences and correlations. We demonstrate that the decoder significantly outperforms the conventional matching algorithm on a variety of noise models, including non-Pauli noise and spatially correlated noise. The algorithm is based on an approximate calculation of the logical channel using a tensor-network description of the noisy state. "
1801_04910_Trade_final20171214.tex," International trade fluxes evolve as countries revise their portfolios of trade products towards economic development. Accordingly products' shares in international trade vary with time, reflecting the transfer of capital between distinct industrial sectors. Here we analyze the share of hundreds of product categories in world trade for four decades and find a scaling law obeyed by the annual variation of product share, which informs us of how capital flows and interacts over the product space. A model of stochastic transfer of capital between products based on the observed scaling relation is proposed and shown to reproduce exactly the empirical share distribution. The model allows analytic solutions as well as numerical simulations, which predict a pseudo-condensation of capital onto few product categories and when it will occur.  At the individual level, our model finds certain products unpredictable, the excess or deficient growth of which with respect to the model prediction is shown to be correlated with the nature of goods. "
1801_09332_Draft_HY_MI_180123_final_arXiv.tex," In this study, we numerically investigated the orbital evolution of cometary dust particles, with special consideration of the initial size frequency distribution (SFD) and different evolutionary tracks according to initial orbit and particle shape. We found that close encounters with planets (mostly Jupiter) are the dominating factor determining the orbital evolution of dust particles. Therefore, the lifetimes of cometary dust particles ( $\sim$ 250 thousand years) are shorter than the Poynting-Robertson lifetime, and only a small fraction of large cometary dust particles can be transferred into orbits with small values of $a$ . The exceptions are dust particles from 2P/Encke and, potentially, active asteroids that have little interaction with Jupiter. We also found that the effect of dust shape, mass density, and SFD were not critical in the total mass supply rate to the Interplanetary Dust Particle (IDP) cloud complex when these quantities are confined by observations of zodiacal light brightness and SFD around the Earth's orbit. When we incorporate a population of fluffy aggregates discovered in the Earth's stratosphere and the coma of 67P/Churyumov-Gerasimenko within the initial ejection, the initial SFD measured at the comae of comets (67P and 81P/Wild 2) can produce the observed SFD around the Earth's orbit. Considering the above effects, we derived the probability of mutual collisions among dust particles within the IDP cloud for the first time in a direct manner via numerical simulation and concluded that mutual collisions are mostly ignorable. "
1801_00037.tex," We discuss the geometry of transverse linear sections of the spinor tenfold $X$ , the connected component of the orthogonal Grassmannian of 5-dimensional isotropic subspaces in a 10-dimensional vector space equipped with a non-degenerate quadratic form. In particular, we show that as soon as the dimension of a linear section of $X$ is at least 5, its integral Chow motive is of Lefschetz type. We discuss classification of smooth linear sections of $X$ of small codimension; in particular we check that there is a unique isomorphism class of smooth hyperplane sections and exactly two isomorphism classes of smooth linear sections of codimension~2. Using this, we define a natural quadratic line complex associated with a linear section of~ $X$ . We also discuss the Hilbert schemes of linear spaces and quadrics on $X$ and its linear sections. "
1801_05530.tex,"\abstract{The purpose of this article is to study an $f$-cosymplectic manifold $M$ admitting Ricci solitons. Here we consider mainly two classes of Ricci solitons on $f$-cosymplectic manifolds. One is the class of contact Ricci solitons. The other is the class of gradient Ricci solitons, for which we give the local classifications of $M$. Meanwhile, we also give some properties of $f$-cosymplectic manifolds.}"
1801_10437_main.tex," {\it Deep learning}  relies on a very specific kind of neural networks: those superposing {\it several} neural layers. In the last few years, deep learning achieved major breakthroughs in many tasks such as image analysis, speech recognition, natural language processing, and so on. Yet, there is no theoretical explanation of this success. In particular, it is not clear why the {\it deeper}  the network, the {\it better}  it actually performs.  We argue that the explanation is intimately connected to a key feature of the {\it data} collected from our surrounding universe to feed the machine learning algorithms: {\it large non-parallelizable logical depth} . Roughly speaking, we conjecture that % this property, also called {\it apparent complexity} , means that the shortest computational descriptions of the universe are algorithms with inherently large computation times, even when a large number of computers are available for parallelization. Interestingly, this conjecture, combined with the folklore conjecture in theoretical computer science that $ P \neq NC$ , explains the success of deep learning. % : some polynomial-time problems seem fundamentally non-parallelizable. This {\it apparent complexity} has been previously studied before in aaronson2014 , where its origin was traced back to the second law of thermodynamics. "
1801_02651_exec_model.tex, abstract
1801_02081_Y._EL_BASSEM_and_M._OULNE.tex," The nuclear structure of even-even and odd lead isotopes ( $^{178-236}$ Pb) is investigated within the Hartree-Fock-Bogoliubov theory. Calculations are performed for a wide range of neutron numbers, starting from the proton-rich side up to the neutron-rich side, by using the SLy4 Skyrme interaction and a new proposed formula for the pairing strength which is more precise for this region of nuclei as we did in previous works in the regions of Neodymium (Nd, Z=60) [http://www.worldscientific.com/doi/abs/10.1142/S0218301315500731{Int. J. Mod. Phys. E 24, 1550073 (2015)}] and Molybdenum (Mo, Z=42) [http://www.sciencedirect.com/science/article/pii/S0375947416301762{Nuc. 	Phys. A 957 22-32 (2017)}] . Such a new pairing strength formula allows reaching exotic nuclei region where the experimental data are not available. Calculated values of various physical quantities such as binding energy, two-neutron separation energy, quadrupole deformation, and rms-radii for protons and neutrons are discussed and compared with experimental data and some estimates of other nuclear models like Finite Range Droplet Model (FRDM), Relativistic Mean Field (RMF) model with NL3 functional (NL3), Density-Dependent Meson-Exchange Relativistic Energy Functional (DD-ME2) and results of Hartree-Fock-Bogoliubov calculations based on the D1S Gogny effective nucleon-nucleon interaction (Gogny D1S). "
1801_10286_unconventionalSC.tex," 	Signatures of nodal line/point superconductivity kim2016,brydon2016 %, as well as surface superconductivity banerjee2015 , have been observed in half-Heusler compounds, such as LnPtBi (Ln = Y, Lu). Topologically non-trivial band structures, as well as topological surface states, has also been confirmed by angular-resolved photoemission spectroscopy in these compounds liuz2016 . In this work, we present a systematical classification of possible gap functions of bulk states and surface states in half-Heusler compounds and the corresponding topological properties based on the representations of crystalline symmetry group. Different from all the previous studies based on four band Luttinger model, our study starts with the six-band Kane model, which involves both four p-orbital type of $\Gamma_8$ bands and two s-orbital type of $\Gamma_6$ bands. Although the $\Gamma_6$ bands are away from the Fermi energy, our results reveal the importance of topological surface states, which originate from the band inversion between $\Gamma_6$ and $\Gamma_8$ bands, in determining surface properties of these compounds in the superconducting regime by combining topological bulk state picture and non-trivial surface state picture. "
1801_09726_main.tex," We study the low temperature properties of a single layer of parahydrogen adsorbed on graphene, by means of Quantum Monte Carlo simulations. The computed phase diagram is very similar to that of helium on the same substrate, featuring commensurate solid phases with fillings 1/3 and 7/16, as well as domain wall phases at intermediate coverages. At higher coverage the system transitions to an incommensurate, compressible phase. Evidence of promotion of molecules to the second layer is observed at a coverage $\sim 0.112$  \Am2, significantly above existing theoretical estimates. "
1801_07163.tex," The Eulerian distribution on the involutions of the symmetric group is unimodal, as shown by Guo and Zeng. In this paper we prove that the Eulerian distribution on the involutions of the hyperoctahedral group, when viewed as a colored permutation group, is unimodal in a similar way and we compute its generating function, using signed quasisymmetric functions. "
1801_07204_ms.tex," Searches are under way in Advanced LIGO and Virgo data for persistent gravitational waves from continuous sources, e.g. rapidly rotating galactic neutron stars, and stochastic sources, e.g. relic gravitational waves from the Big Bang or superposition of distant astrophysical events such as mergers of black holes or neutron stars. These searches can be degraded by the presence of narrow spectral artifacts (lines) due to instrumental or environmental disturbances. We describe a variety of methods used for finding, identifying and mitigating these artifacts, illustrated with particular examples. Results are provided in the form of lists of line artifacts that can safely be treated as non-astrophysical. Such lists are used to improve the efficiencies and sensitivities of continuous and stochastic gravitational wave searches by allowing vetoes of false outliers and permitting data cleaning.   "
1801_03128_Trojan.tex,{}{}{}{}
1801_07930.tex," In this paper we study a relation between the cohomology ring of a regular nilpotent Hessenberg variety and Schubert polynomials. To describe an explicit presentation of the cohomology ring of a regular nilpotent Hessenberg variety, polynomials $f_{i,j}$ were introduced by Abe-Harada-Horiguchi-Masuda. We show that every polynomial $f_{i,j}$ is an alternating sum of certain Schubert polynomials. "
1801_09973_main.tex," %Event-based Social Networks (EBSN) have become extremely popular in recent years. %In this new type of social media, users organize, manage and share social events. %In conjunction with EBSNs, several % entities such as event planning and marketing companies, organizations, as well as venues, organize and manage numerous social events (e.g., festivals, conferences, parties).  A major challenge for social event organizers (e.g., event planning and marketing companies, venues) is attracting the maximum number of participants, since it has great impact on the success of the event, and, consequently, the expected gains (e.g., revenue, artist/brand publicity). In this paper, we introduce the  Social Event Scheduling ( \ses) problem,  which schedules a set of social events considering user preferences and behavior, events' spatiotemporal conflicts, and competing events, in order to maximize the overall number of attendees. We show that \ses is strongly NP-hard, even in highly restricted instances. To cope with the hardness of the SES problem we design a greedy approximation algorithm. Finally, we evaluate our method experimentally using a dataset from the Meetup event-based social network.%   "
1801_08233_2d_revised_final_forarXiv.tex," We perform comprehensive density-functional theory calculations on strained two-dimensional phosphorus (P), arsenic (As) and antimony (Sb) in the monolayer, bilayer, and bulk  $\alpha$ -phase, from which we compute the key mechanical and electronic properties of these materials.  % Specifically, we compute their electronic band structures, band gaps, and charge-carrier effective masses, and identify the qualitative electronic and structural transitions that may occur. % Moreover, we compute the elastic properties such as the Young's modulus $Y$ ; shear modulus $G$ ; bulk modulus $B$ ; and Poisson ratio $\nu$  and present their isotropic averages of as well as their dependence on the in-plane orientation, for which the relevant expressions are derived. % We predict strain-induced  Dirac states in the  monolayers of As and Sb and  the bilayers of P, As, and Sb, as well as the possible existence of Weyl states  in the bulk phases of P and As. % \edit{These phases are predicted to support charge velocities up to $10^6$~$ms^{-1}$ and, in some highly anisotropic cases, permit one-dimensional ballistic conductivity in the puckered direction.} % We also predict  numerous band gap transitions for moderate in-plane stresses. % Our results contribute to the mounting evidence for the utility of these materials, made possible by their broad range in tuneable properties, and facilitate the directed exploration of their potential application in next-generation electronics. "
1801_03350_main.tex,"\abstract{  The study of identified particle production in proton-proton (s$) and event charged-particle multiplicity is a key tool for understanding similarities and differences between small and large collision systems.  We report on new measurements of the production of identified particles and their dependence on multiplicity and $s$. \\  Latest results for light flavor hadrons, comprising s~=~5.02, 7$, and 13\,TeV\,---\,measurements for  $s~=~5.02$\,TeV\pp collisions are reported here for the first time.  The measured minimum bias s~=~7$ and $s~=~13$\,TeV. Results are compared to measurements at lower collision energies as well as to those in proton-lead (\ppb) and  lead-lead (s_{s_{\rm NN}~=~2.76$\,TeV. \\  The results unveil intriguing similarities among collision systems at different center-of-mass energies. The production rates of strange hadrons are found to increase more than those of non-strange particles, showing an enhancement pattern with multiplicity which does not depend  on the collision energy. These yield ratios take values which are alike for small systems at comparable multiplicities, and show smooth evolution with multiplicity across all collision systems; they tend to approach those measured in \pb collisions.  Although, the multiplicity dependence of spectral shapes can be qualitatively described by general-purpose Monte Carlo (MC) event generators, the evolution of integrated yield ratios is barely (or not) captured at all by MC model predictions.          }"
1801_08551_HWET_1overM.tex," WIMP-nucleon scattering is analyzed at order $1/M$ in Heavy WIMP Effective Theory. The $1/M$ power corrections, where $M\gg m_W$ is the WIMP mass, distinguish between different underlying UV models with the same universal limit and their impact on direct detection rates can be enhanced relative to naive expectations due to generic amplitude-level cancellations at leading order.  The necessary one- and two-loop matching calculations onto the low-energy effective theory for WIMP interactions with Standard Model quarks and gluons are performed for the case of an electroweak SU(2) triplet WIMP, considering both the cases of elementary fermions and composite scalars.  The low-velocity WIMP-nucleon scattering cross section is evaluated and compared with current experimental limits and projected future sensitivities. Our results provide the most robust prediction for electroweak triplet Majorana fermion dark matter direct detection rates; for this case, a cancellation between two sources of power corrections yields a small total $1/M$ correction, and a total cross section close to the universal limit for $M \rm few \rm GeV$ . For the SU(2) composite scalar, the $1/M$ corrections introduce dependence on underlying strong dynamics. Using a leading chiral logarithm evaluation, the total $1/M$ correction has a larger magnitude and uncertainty than in the fermionic case, with a sign that further suppresses the total cross section. These examples provide definite targets for future direct detection experiments and motivate large scale detectors capable of probing to the neutrino floor in the TeV mass regime. "
1801_09948_FBohn_etal_manuscript_naturCommun.tex," Many systems crackle, from earthquakes and financial market to Barkhausen effect in ferromagnetic materials. Despite the diversity in essence, the noise emitted in these dynamical systems consists of avalanche-like events with broad range of sizes and durations, characterized by power-law avalanche distributions and typical average avalanche shape that are signatures dependent on the universality class of the underlying dynamics. Here we focus on the crackling noise in ferromagnets and scrutinize the traditional statistics of Barkhausen avalanches in polycrystalline and amorphous ferromagnetic films having different thicknesses. We show how scaling exponents and average shape of the avalanches evolve with the structural character of the materials and film thickness. We find quantitative agreement between experiment and theoretical predictions of models for the magnetic domain wall dynamics, and then elucidate the universality classes of Barkhausen avalanches in ferromagnetic films. Thereby, we observe for the first time the dimensional crossover in the domain wall dynamics, and the outcomes of the interplay between system dimensionality and range of interactions governing the domain wall dynamics on Barkhausen avalanches. "
abstract.tex," Data minimisation is a privacy enhancing principle, stating that personal data collected should be no more than necessary for the specific purpose consented by the user. Checking that a program satisfies the data minimisation principle is not easy, even for the simple case when considering deterministic programs-as-functions. In this paper we prove (im)possibility results concerning runtime monitoring of (non-)minimality for deterministic programs both when the program has one input source (monolithic) and for the more general case when inputs come from independent sources (distributed case). We propose monitoring mechanisms where a monitor observes the inputs and the outputs of a program, to detect violation of data minimisation policies. We show that monitorability of (non) minimality is decidable only for specific cases, and detection of satisfaction of different notions of minimality in undecidable in general. That said, we show that under certain conditions monitorability is decidable and we provide an algorithm and a bound to check such properties in a pre-deployment controlled environment, also being able to compute a minimiser for the given program. Finally, we provide a proof-of-concept implementation for both offline and online monitoring and apply that to some case studies. "
project_abstract.tex,"  The design of a building requires an architect to balance a wide range of constraints: aesthetic, geometric, usability, lighting, safety, etc. At the same time, there are often a multiplicity of diverse designs that can meet these constraints equally well. Architects must use their skills and artistic vision to explore these rich but highly constrained design spaces. A number of computer-aided design tools use automation to provide useful analytical data and optimal designs with respect to certain fitness criteria. However, this automation can come at the expense of a designer's creative control.  We propose \DOME, a user-in-the-loop system for computer-aided design exploration that balances automation and control by efficiently exploring, analyzing, and filtering the space of environment layouts to better inform an architect's decision-making. At each design iteration, \DOME provides a set of diverse designs which satisfy user-defined constraints and optimality criteria within a user defined parameterization of the design space. The user then selects a design and performs a similar optimization with the same or different parameters and objectives. This exploration process can be repeated as many times as the designer wishes. Our user studies indicates that \DOME, with its diversity-based approach, improves the efficiency and effectiveness of even novice users with minimal training, without compromising the quality of their designs.  %We propose \DOME, a user-in-the-loop system for computer-aided design exploration that balances automation and creative control. Rather than taking over the design process, \DOME's main goal is to facilitate exploration and inform an architect's decision-making. At each design iteration, \DOME provides a set of diverse designs which satisfy user-defined constraints and optimality criteria within a user defined parameterization of the design space. The user then selects a design, and performs a new diversity optimization with the same or different parameters and objectives. This exploration process can be repeated as many times as the designer wishes. Our user study indicates that \DOME, with its diversity-based approach, improves the efficiency and effectiveness of even novice users with minimal training, without compromising the quality of their designs.  %A key novelty of our approach is a hierarchical multi-objective diversity formulation based on  spatial analysis framework.  %Our main contributions are as follows: a) We propose a user-in-loop system for computer assisted design exploration. b) We propose a spatial analysis approach as the basis of an iterative optimization framework. c) We develop an efficient hierarchical diversity optimization method. d) We demonstrate our framework within the context of an industry standard system.   %d) We evaluate the system with a user-study that involves both inexperienced users, and domain experts. d) We provide an efficient GPU implementation of standard space analysis metrics.   %There is an increasing demand for computational analysis of uraban structures in order to help the designers achieve more efficient designs. The goal of this work is to complete the bridge between architectural desing and computational systems, by not only analyzing the environment within the accepted and popular frame-works of architecture community, but also providing meaningful suggestions as opposed to mere analytic data. We present a framework which connects the loop between environment features, computational analysis, artificial intelligence, and the architect's decision-making. This framework, while being minimal to prove the concept of this connection, can be easily etxtended to include complicated artificial intelligence reasoning from the analysis, and in depth environment analysis. We first conduct static and dynamic environment analysis to obtain some features of the environment. Aftewards, we start a user-in-the-loop optimization over these features, where the optimization tries to maximize the calculated features while the user can interactively guide the optimization by making mid-way choices. We also exploit a many-world idea, where instead of proposing one solution, the system provides several diverse optimal solutions to the agent at each step, and the choice of the user will then guide the continuation of the optimization. Therefore, the contribution of this work is threefold: providing suggestions for environment modification, including the human expert decisions in the optimization process (user-in-the-loop), and providing many-world solutions to further extend the choices of the architects while not overwhelming them with huge amount of raw information. % %Using optimization with architecture specific and crowd related metrics to provide intelligent suggestions to an architectural designer. % % If I remove the line below latex cannot write the pdf. VERY WEIRD! %Maybe use interactive multi-objective optimization, as part of the design process.  "
