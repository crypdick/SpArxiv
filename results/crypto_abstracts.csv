old_file,abstract
1801_05050_SfyrisBoronNitride.tex," We lay down a nonlinear elastic constitutive framework for the modeling of some 2D crystals of current interest. The 2D crystals we treat are graphene, hexagonal boron nitride and some metal dichalcogenides: molybdenium disulfide (MoS $_2$ ), tungsten selenium (WSe $_2$ ), and niobium diselenide (NbSe $_2$ ). We first find their arithmetic symmetries by using the theory of monoatomic and diatomic 2-nets. Then, by confinement to weak transformation neighbourhoods and by applying the Cauchy-Born rule we are able to use the symmetries continuum mechanics utilizes: geometric symmetries. We give the complete and irreducible representation for energies depending on an in-plane measure, the curvature tensor and the shift vector. This is done for the symmetry hierarchies that describe how symmetry changes at the continuum level: $6 \nu 2 \nu \rightarrow \mathcal C_1$ for monoatomic 2-nets and $6 \nu 1 \nu \rightarrow \mathcal C_1$ for diatomic two nets. Having these energies at hand we are able to evaluate stresses and couple stresses for each symmetry regime.  "
1801_00453_main.tex," Effective presentation skills can help to succeed in business, career and academy. This paper presents the design of speech assessment during the oral presentation and the algorithm for speech evaluation based on criteria of optimal intonation. As the pace of the speech and its optimal intonation varies from language to language, developing an automatic identification of language during the presentation is required. Proposed algorithm was tested with presentations delivered in Kazakh language. For testing purposes the features of Kazakh phonemes were extracted using MFCC and PLP methods and created a Hidden Markov Model (HMM) c22, c22 of Kazakh phonemes. Kazakh vowel formants were defined and the correlation between the deviation rate in fundamental frequency and the liveliness of the speech to evaluate intonation of the presentation was analyzed. It was established that the threshold value between monotone and dynamic speech is 0.16 and the error for intonation evaluation is 19 \%.  "
1801_03581_biases.tex," Automated particle locating algorithms have revolutionized microscopy image analysis, enabling researchers to rapidly locate many particles to within a few pixels in a microscope image. The vast majority of these algorithms operate through heuristic approaches inspired by computer vision, such as identifying particles with a blob detection. While rapid, these algorithms are plagued by biases~ Baumgartl2005, Lu2013, Gao2009 , and many researchers still frequently ignore or understate these biases. In this paper, we examine sources of biases in particle localization. Rather than exhaustively examine all possible sources of bias, we illustrate their scale, the large number of sources, and the difficulty of correcting the biases with a heuristic method. We do this by generating a series of simple images, introducing sources of bias one at a time. Using these images, we examine the performance of two heuristic algorithms throughout the process: a centroid algorithm and a Gaussian fitting algorithm. We contrast the two heuristic methods with a new approach based on reconstructing an image with a generative model to fit the data (Parameter Extraction from Reconstructing Images, or PERI). While the heuristic approaches produce considerable biases even on unrealistically simple images, the reconstruction-based approach accurately measures particle positions even in complex, highly realistic images. We close by reiterating the fundamental reason that a reconstruction-based approach accurately extracts particle positions -- any imperfections in the fit both demonstrate which sources of systematic error are still present and provide a roadmap to incorporating them. "
1801_03033_FermiSymposium_Xiaping_new.tex,"In this work, we compare the $\gamma$-ray spectra available in literature from 11 middle aged supernova remnants (SNRs) interacting with molecular clouds (MCs). It is found that 5 remnants prefer a smoothly broken power law proton spectrum with similar power law index but different break energy. The rest of the SNRs need updated data to test whether a spectral break is preferred in the proton spectrum. Then we compare the $\gamma$-ray spectra from all 11 SNRs with the prediction from widely accepted escaping scenario and direct interaction scenario. We show that current $\gamma$-ray data is inconsistent with the escaping model statistically, as it predicts a diversity of $\gamma$-ray spectra which is not detected in the observation. We also find that ambient CRs can be very important for the $\gamma$-ray emission in the MCs external to W28 and W44, which requires further investigation. In the direct interaction scenario, we focus on re-acceleration of pre-existing ambient CRs. The model can produce the overall profile of $\gamma$-ray data with different acceleration time, but it suggests a transition of seed particles in the evolution of SNR. Whether such transition indeed exists has to be tested by future observation. In the end, we propose that radiative SNR without MC interaction can also produce a significant amount of $\gamma$-ray emission. One good candidate is S147. With accumulated Fermi data and CTA in future we expect to detect more remnants like S147. "
1801_06907_si29.tex,"  Using density functional molecular dynamics simulations, we study  the behavior of different hydrogen-oxygen compounds at megabar  pressures and several thousands of degrees Kelvin where water has  been predicted to occur in superionic form. When we study the close  packed hcp and dhcp structures of superionic water, we find that  they have comparable Gibbs free energies to the fcc structure that  we predicted previously [Phys. Rev. Lett., 110 (2013) 151102] .  Then we present a comprehensive comparison of different superionic  water candidate structures with $P2_1$ , $P2_1/c$ , $P3_121$ , $Pcca$ ,  $C2/m$ , and $Pa\bar 3$ symmetry that are based on published  ground-state structures. We find that the $P2_1$ and $P2_1/c$  structures transform into a different superionic structure with  $P2_1/c$ symmetry, which at 4000 K has a lower Gibbs free energy than fcc for  pressures higher than 22.8 $\pm$ 0.5 Mbar. This novel structure may  also be obtained by distorting a hcp supercell. Finally we show that  H $_2$ O $_2$ and H $_9$ O $_4$ structures will also assume a superionic  state at elevated temperatures. Based on Gibbs free energy  calculations at 5000 K, we predict that superionic water decompose  into H $_2$ O $_2$ and H $_9$ O $_4$ at 68.7 $\pm$ 0.5 Mbar. "
1801_08186_main.tex," In this paper, we address referring expression comprehension: localizing an image region described by a natural language expression. While most recent work treats expressions as a single unit, we propose to decompose them into three modular components related to subject appearance, location, and relationship to other objects. This allows us to flexibly adapt to expressions containing different types of information in an end-to-end framework. In our model, which we call the Modular Attention Network (MAttNet), two types of attention are utilized: language-based attention that learns the module weights as well as the word/phrase attention that each module should focus on; and visual attention that allows the subject and relationship modules to focus on relevant image components. Module weights combine scores from all three modules dynamically to output an overall score. Experiments show that MAttNet outperforms previous state-of-art methods by a large margin on both bounding-box-level and pixel-level comprehension tasks. Project and Demo page: \href{http://gpuvision.cs.unc.edu/refer/comprehension{gpuvision.cs.unc.edu/refer/comprehension}} "
1801_03832_LaibacherTamma_TowardQuantumComputationalSupremacy.tex,
1801_00410_qLMS_enhanced_updated_review.tex," In this work, a new class of stochastic gradient algorithm is developed based on $q$ -calculus. Unlike the existing $q$ -LMS algorithm, the proposed approach fully utilizes the concept of $q$ -calculus by incorporating time-varying $q$ parameter. The proposed enhanced $q$ -LMS ( $Eq$ -LMS) algorithm utilizes a novel, parameterless concept of error-correlation energy and normalization of signal to ensure high convergence, stability and low steady-state error. The proposed algorithm automatically adapts the learning rate with respect to the error. For the evaluation purpose the system identification problem is considered. Extensive experiments show better performance of the proposed $Eq$ -LMS algorithm compared to the standard $q$ -LMS approach.  "
1801_01045_main.tex,"\abstract{ In this work we have performed a series of simulations of the atmosphere of GJ~1214b assuming different metallicities using the Met Office Unified Model (UM). The UM is a general circulation model (GCM) that solves the deep, non-hydrostatic equations of motion and uses a flexible and accurate radiative transfer scheme, based on the two-stream and correlated-$k$ approximations, to calculate the heating rates. In this work we consistently couple a well-tested Gibbs energy minimisation scheme to solve for the chemical equilibrium abundances locally in each grid cell for a general set of elemental abundances, further improving the flexibility and accuracy of the model. As the metallicity of the atmosphere is increased we find significant changes in the dynamical and thermal structure, with subsequent implications for the simulated phase curve. The trends that we find are qualitatively consistent with previous works, though with quantitative differences. We investigate in detail the effect of increasing the metallicity by splitting the mechanism into constituents, involving the mean molecular weight, the heat capacity and the opacities. We find the opacity effect to be the dominant mechanism in altering the circulation and thermal structure. This result highlights the importance of accurately computing the opacities and radiative transfer in 3D GCMs. }"
1801_05907.tex," In this paper, we derive estimates for scalar curvature type equations with more singular right hand side. As an application, we prove Donaldson's conjecture on the equivalence between geodesic stability and existence of cscK when $Aut_0(M,J)\neq0$ . Moreover, we also show that when $Aut_0(M,J)\neq0$ , the properness of $K$ -energy with respect to a suitably defined distance implies the existence of cscK. "
1801_03226_Li-Wang.tex," 	Graph Convolutional Neural Networks (Graph CNNs) are generalizations of classical CNNs to handle graph data such as molecular data, point could and social networks. Current filters in graph CNNs are built for fixed and shared graph structure. However, for most real data, the graph structures varies in both size and connectivity. The paper proposes a generalized and flexible graph CNN taking data of arbitrary graph structure as input. In that way a task-driven adaptive graph is learned for each graph data while training. To efficiently learn the graph, a distance metric learning is proposed. Extensive experiments on nine graph-structured datasets have demonstrated the superior performance improvement on both convergence speed and predictive accuracy. "
1801_04334_TIE_Network.tex," Chest X-rays are one of the most common radiological examinations in daily clinical routines. Reporting thorax diseases using chest X-rays is often an entry-level task for radiologist trainees. Yet, reading a chest X-ray image remains a challenging job for learning-oriented machine intelligence, due to (1) shortage of large-scale machine-learnable medical image datasets, and (2) lack of techniques that can mimic the high-level reasoning of human radiologists that requires years of knowledge accumulation and professional training. In this paper, we show the clinical free-text radiological reports%, that accompany X-ray images in hospital picture and archiving communication systems, can be utilized as a priori knowledge for tackling these two key problems. We propose a novel Text-Image Embedding network (TieNet) for extracting the distinctive image and text representations. Multi-level attention models are integrated into an end-to-end trainable CNN-RNN architecture for highlighting the meaningful text words and image regions. We first apply TieNet to classify the chest X-rays by using both image features and text embeddings extracted from associated reports. The proposed auto-annotation framework achieves high accuracy (over 0.9 on average in AUCs) in assigning disease labels for our hand-label evaluation dataset. %We then demonstrate the minimal amount of `ground truth' labels (NLP mined disease keywords) required for achieving similar performance as previous rule-based method. Furthermore, we transform the TieNet into a chest X-ray reporting system. It simulates the reporting process and can output disease classification and a preliminary report together%, with X-ray images being the only input . The classification results are significantly improved (6 \% increase on average in AUCs) compared to the state-of-the-art baseline on an unseen and hand-labeled dataset (OpenI). "
1801_00036_report.tex," A graph database is a database where the data structures for the schema and/or instances are modeled as a (labeled)(directed) graph or generalizations of it, and where querying is expressed by graph-oriented operations and type constructors.  In this article we present the basic notions of graph databases, give an historical overview of its main development, and study the main current systems that implement them. "
1801_00962_PhysRevBKlyushinaetallv1.tex," The magnetic properties of the two-dimensional, S=1 honeycomb antiferromagnet BaNi $_2$ V $_2$ O $_8$ have been comprehensively studied using DC susceptibility measurements and inelastic neutron scattering techniques. The magnetic excitation spectrum is found to be dispersionless within experimental resolution between the honeycomb layers, while it disperses strongly within the honeycomb plane where it consists of two gapped spin-wave modes. The magnetic excitations are compared to linear spin-wave theory allowing the Hamiltonian to be determined. The first- and second-neighbour magnetic exchange interactions are antiferromagnetic and lie within the ranges 10.90meV $\le$ J $_n$ $\le$ 13.35 meV and 0.85meV $\le$ J $_{nn}$ $\le$ 1.65 meV respectively. The interplane coupling J $_{out}$ is four orders of magnitude weaker than the intraplane interactions, confirming the highly two-dimensional magnetic behaviour of this compound. The sizes of the energy gaps are used to extract the magnetic anisotropies and reveal substantial easy-plane anisotropy and a very weak in-plane easy-axis anisotropy. Together these results reveal that BaNi $_2$ V $_2$ O $_8$ is a candidate compound for the investigation of vortex excitations and Berezinsky-Kosterliz-Thouless phenomenona. "
1801_04528_main.tex," % Our message: \newline % (1) human communication is not random. Our entropy measures confirms that intuition, in other words - make sense. \newline % (2) Proposed novelty: describe dynamics of temporal network (as event sequence/stream) with a vector or single number (by fitting logistic regression and taking one of its parameters) \newline % (3) Application: we can show that in presented datasets we can observe changes in entropy and we can explain it e.g. in NetSense while students getting know each other during semesters (time) entropy is decreasing. That can be understand as kind of burning out of the network capability to be dynamic. %Human communication at first glance looks like random process but deeper analysis shows that it is a process very different from random. In this work we propose set of new entropy-based measures for human communication dynamic given with temporal network representation – event sequence. We examined four dataset of human communication with different characteristics as well as random sequences. Application of entropy for human communication not only reveals non-randomness of this process in temporal networks but also give a foundation for further analysis. We provide some hypothesis which explains dynamics of examined datasets and show potential of proposed measurements. Human communication is commonly represented as a temporal social network, and evaluated in terms of its uniqueness. We propose a set of new entropy-based measures for human communication dynamics represented within the temporal social network as event sequences. Using real world datasets and random interaction series of different types we find that real human contact events always significantly differ from random ones. This human distinctiveness increases over time and by means of the proposed entropy measures, we can observe sociological processes that take place within dynamic communities. "
1801_05578_pifm_arxiv.tex," Quantum coherence can be used to infer presence of a detector without triggering it. Here we point out that according to quantum formalism such interaction-free measurements cannot be perfect, i.e. in a single-shot experiment one has strictly positive probability to activate the detector. We provide a quantitative relation between the probability of activation and probability of inconclusive interaction-free measurement in quantum theory and in a more general framework of density cubes. It turns out that the latter does allow for perfect interaction-free measurements. Their absence is therefore a natural postulate expected to hold in all physical theories. "
1801_03854.tex," A mixed boundary value problem for the diffusion equation in non-homogeneous media partial differential equation is reduced to a system of direct segregated parametrix-based Boundary-Domain Integral Equations (BDIEs). We use a parametrix different from the one employed by Mikhailov in localised,carlos2 and Chkadua, Mikhailov, Natroshvili in mikhailov1 . We prove the equivalence between the original BVP and the corresponding BDIE system. The invertibility and Fredholm properties of the boundary-domain integral operators are also analysed. "
1801_04889_final_release_15.2018.tex," In this paper we give sufficient conditions for a free product of residually finite groups to admit an embeddable box space. This generalizes the constructions of Arzhantseva, Guentner and Spakula in AGS and gives a new class of non-amenable metric spaces with bounded geometry which coarsely embeds into Hilbert space.\\ "
1801_03837_Text.tex," Cavity mode theory and analysis of open cavities and plasmonic particles is an essential component of optical resonator physics, offering considerable insight and efficiency for connecting to classical and quantum optical properties such as the Purcell effect. However, obtaining the dissipative modes in normalized form for arbitrarily shaped open cavity systems is notoriously difficult, often involving complex spatial integrations, even after performing the necessary full space solutions to Maxwell's equations. The formal solutions are termed  quasinormal modes which are known to diverge in space, and additional techniques are frequently required to obtain more accurate field representations in the far field. In this work we introduce a new finite-difference time-domain technique that can obtain normalized quasinormal modes using a simple dipole-excitation source and an inverse Green function technique, in real frequency space, without having to perform any spatial integrations. Moreover, we show how these modes are naturally regularized to ensure the correct field decay behaviour in the far field, and thus can be used at any position within and outside the resonator. We term these modes ``regularized quasinormal modes'' and show the reliability and generality of the theory, by studying the generalized Purcell factor of quantum dipole emitters near metallic nanoresonators, hybrid devices with metal nanoparticles coupled to dielectric waveguides, as well as coupled cavity-waveguides in photonic crystals slabs. We also directly compare our results with full-dipole simulations of Maxwell's equations without any approximations and show excellent agreement. "
1801_01607_EdgeModesHorizon.tex," We consider propagation of Bogoliubov quasiparticles in the presence of a step-like BEC horizon -- a stationary superfluid flow where the superfluid velocity abruptly changes from subsonic to supersonic. We argue that the astrophysical analogue of this system is a black hole with a small mass in a theory whose UV completion breaks Lorentz symmetry at short distances. We solve the corresponding Bogoliubov-de Gennes equations and find that the scattering process responsible for Hawking radiation also necessarily produces an evanescent tail of negative-norm quasiparticles localized near the horizon. These evanescent modes, which we dub ``sonic hairs,"" are a direct result of the Lorentz-violating non-linear dispersion relation. Even though the localized modes do not enter the S-matrix they must be accounted for in order to obtain the Hawking distribution. Additionally, we show that the black hole's sonic hair undergoes quantum-interference effects with the outgoing Hawking particles which dresses physical observables near the event-horizon. We conclude by discussing possible connections between these modes and the black-hole information problem. "
1801_05363_Article-arXiv.tex," In this work, a non intrusive load disaggregation scheme is proposed. By using a kernel based nonlinear regression strategy, the switching dynamic of an electric network, simulated as a set of RLC circuits with chaotic switching, is approximated using a time series of the total power consumption. The results suggest that the employed methodology can be useful in the design of efficient load disaggregation schemes. "
1801_00941.tex," We consider stable solutions of semilinear equations in a very general setting. The equation is set on a Polish topological space endowed with a measure and the linear operator is induced by a carr \'e du champs (equivalently, the equation is set in a diffusion Markov triple). Under suitable curvature dimension conditions, we establish that stable solutions with integrable carr \'e du champs are necessarily constant (weaker conditions characterize the structure of the carr \'e du champs and carr \'e du champ it \'er \'e). The proofs are based on a geometric Poincar F formula in this setting. rom the general theorems established, several previous results are obtained as particular cases and new ones are provided as well. "
1801_06409_zetaOphiuchi.tex,"We present the results of our spectroscopic monitoring campaign of $\zeta$\,Oph, carried out at the University observatory Jena with the spectrograph FLECHAS between July 2015 and September 2016. The main aim of the project is to determine the radial velocity of the star precisely, as a wide range of radial velocity measurements of $\zeta$\,Oph are given in the literature. Beside the proper motion and parallax, the radial velocity is an important input parameter for the calculation of the space motion of the star. $\zeta$\,Oph is considered to be a runaway star and potential former companion of the progenitor star of the pulsar PSR\,J1932+1059, which both may have been located in a binary system and were then released during a supernova explosion about 1\,Myr ago in the Upper Scorpius OB association. For the calculation that the pulsar and $\zeta$\,Oph could have been at the same place, a radial velocity of $-9.0$\,km/s for $\zeta$\,Oph was used in the literature. By analysing the hydrogen and helium lines in 48 FLECHAS spectra, we determined the radial velocity of $\zeta$\,Oph to be $12.2\pm3.3$\,km/s and the projected rotational velocity to $432\pm16$\,km/s with no indication for variability."
1801_00720_WTF_GTC_spectro.tex,{}{}{}{}
1801_02236_lehmann.tex,"\abstract{In this final chapter, we consider the state-of-the-art for spreading in social systems and discuss the future of the field. As part of this reflection, we identify a set of key challenges ahead. The challenges include the following questions: how can we improve the quality, quantity, extent, and accessibility of datasets? How can we extract more information from limited datasets? How can we take individual cognition and decision making processes into account? How can we incorporate other complexity of the real contagion processes? Finally, how can we translate research into positive real-world impact? In the following, we provide more context for each of these open questions.}"
1801_08836_jltp_mfm.tex,"  Temperature and field dependent measurements of the electrical  resistance of different natural graphite samples, suggest the  existence of superconductivity at room temperature in some regions  of the samples. To verify whether dissipationless electrical  currents are responsible for the trapped magnetic flux inferred from  electrical resistance measurements, we localized them using magnetic  force microscopy on a natural graphite sample in remanent state  after applying a magnetic field. The obtained evidence indicates  that at room temperature a permanent current flows at the border of  the trapped flux region. The current path vanishes at the same  transition temperature $T_c\approx370$ ~K as the one obtained from  electrical resistance measurements on the same sample. This sudden  decrease of the phase is different from what is expected for a  ferromagnetic material. Time dependent measurements of the signal  show the typical behavior of flux creep of a permanent current  flowing in a superconductor. The overall results support the  existence of room-temperature superconductivity at certain regions  in the graphite structure and indicate that magnetic force  microscopy is suitable to localize them. Magnetic coupling is  excluded as origin of the observed phase signal. "
1801_08110_paper.tex," Detecting objects and estimating their pose remains as one of the major challenges of the computer vision research community. There exists a compromise between localizing the objects and estimating their viewpoints. The detector ideally needs to be view-invariant, while the pose estimation process should be able to generalize towards the category-level. This work is an exploration of using deep learning models for solving both problems simultaneously. For doing so, we propose three novel deep learning architectures, which are able to perform a joint detection and pose estimation, where we gradually decouple the two tasks. We also investigate whether the pose estimation problem should be solved as a classification or regression problem, being this still an open question in the computer vision community. We detail a comparative analysis of all our solutions and the methods that currently define the state of the art for this problem. We use PASCAL3D+ and ObjectNet3D datasets to present the thorough experimental evaluation and main results. With the proposed models we achieve the state-of-the-art performance in both datasets. "
1801_00329_main.tex,"%  <- trailing '%' for backward compatibility of .sty file Recent advances of derivative-free optimization allow efficient approximating the global optimal solutions of sophisticated functions, such as functions with many local optima, non-differentiable and non-continuous functions. This article describes the ZOOpt \url{https://github.com/eyounx/ZOOpt} toolbox that provides efficient derivative-free solvers and are designed easy to use. ZOOpt provides a Python package for single-thread optimization, and a light-weighted distributed version with the help of the Julia language for Python described functions. ZOOpt toolbox particularly focuses on optimization problems in machine learning, addressing high-dimensional, noisy, and large-scale problems. The toolbox is being maintained toward ready-to-use tool in real-world machine learning tasks. "
1801_06836_peak-locking.tex," Shack-Hartmann wavefront sensing relies on accurate spot centre measurement. Several algorithms were developed with this aim, mostly focused on precision, i.e. minimizing random errors. In the solar and extended scene community, the importance of the accuracy (bias error due to peak-locking, quantisation or sampling) of the centroid determination was identified and solutions proposed. But these solutions only allow partial bias corrections. To date, no systematic study of the bias error was conducted. This article bridges the gap by quantifying the bias error for different correlation peak-finding algorithms and types of sub-aperture images and by proposing a practical solution to minimize its effects. Four classes of sub-aperture images (point source, elongated laser guide star, crowded field and solar extended scene) together with five types of peak-finding algorithms (1D parabola, the centre of gravity, Gaussian, 2D quadratic polynomial and pyramid) are considered, in a variety of signal-to-noise conditions. The best performing peak-finding algorithm depends on the sub-aperture image type, but none is satisfactory to both bias and random errors. A practical solution is proposed that relies on the anti-symmetric response of the bias to the sub-pixel position of the true centre. The solution decreases the bias by a factor of $\sim 7$ to values of $pix$ . The computational cost is typically twice of current cross-correlation algorithms. "
1801_05691_Bohmian_Earth_Article.tex," For quantum systems, we expect to see classical behavior at the limit of large quantum numbers. Hence, we apply Bohmian approach to describe the Earth evolution around the Sun. We obtain possible trajectories of the Earth system with different initial conditions which converge to a definite stable orbit after a given time, known as the Kepler orbit. The trajectories have resulted from the guiding equation $p=\nabla S$ in Bohmian mechanics which relates the momentum of the system to the phase part of the wave function. Except for some special situations, Bohmian trajectories are not Newtonian in character. We show that the classical behavior of the Earth can be described as the consequence of the guiding equation at the limit of large quantum numbers. "
1801_00240_typeA.tex," In this paper, we present a simple lattice-theoretic characterization for Euclidean building of type A. We introduce a class of modular lattices, called uniform modular lattices, and show that uniform modular lattices and Euclidean buildings of type A constitute the same object. This is a Euclidean counterpart of the well-known equivalence between projective geometries ( $\simeq$ complemented modular lattices) and spherical buildings of type A. "
1801_09366_f.tex," In this note, we concentrate on the backward error of the equality constrained indefinite least squares problem. For the normwise backward error of the equality constrained indefinite least square problem, we adopt the linearization method to derive the tight estimate for the exact backward normwise error. The numerical examples show that the linearization estimate is effective for the normwise backward errors. "
1801_00158_0Abstract.tex," For a pair $(G,G')=(O(n+1,1), O(n,1))$  of reductive groups,  we investigate intertwining operators (symmetry breaking operators) between principal series representations  $I_\delta(V,\lambda )$ of $G$ ,  and $J_\varepsilon(W,\nu)$ of the subgroup $G'$ .  The representations are parametrized by finite-dimensional representations $V$ ,  $W$ of $O(n)$ respectively of $O(n-1)$ , characters $\delta$ , $\varepsilon$ of $O(1)$ ,  and $\mathbb C$ . Let $[V:W]$ be the multiplicity of $W$  occurring in the restriction $V|_{O(n-1)}$ ,  which is either 0 or 1.  If $[V:W] \ne 0$  then  we construct a meromorphic family of symmetry breaking operators and prove that  $  \mathbb{C} Hom_{G'}(I_{G', J_{\varepsilon}(W, \nu)) $  is nonzero for all the parameters $\lambda$ , $\nu$ and $\delta$ , $\varepsilon$ ,  whereas if $[V:W] = 0$ there may exist sporadic differential symmetry breaking operators. Moreover we obtain a complete classification of symmetry breaking operators in the special case  $ (V,W)=(\mathbb{C}^{n}), \mathbb{C}^{n-1}))$ .   We use this information to determine the space of symmetry breaking operators  for any pair of irreducible representations of $G$ and the subgroup $G'$  with trivial infinitesimal character $\rho $ .  Furthermore we prove the multiplicity conjecture by B.~Gross and D.~Prasad for tempered principal series representations of $(SO(n+1,1), SO(n,1))$  and also for 3 tempered representations $\Pi, \pi, \varpi$ of  $SO(2m+2,1)$ , $SO(2m+1,1)$ and $SO(2m,1)$  with trivial infinitesimal character $\rho$ . We also apply our main results to find periods of irreducible representations of the Lorentz group having nonzero $({g}, K)$ -cohomologies.   This article is an extension of  [Memoirs Amer.~Math.~Soc. 2015]  that treated spherical principal series representations.     "
1801_03323.tex," We discuss the quantum Hall effect on a single-layer graphene in the framework of noncommutative (NC) phase space. We find it induces a shift in the Hall resistivity. Furthermore, comparison with experimental data reveals an upper bound on the magnitude of the momentum NC parameter $\eta$ in about $\etaeV/c$ . "
1801_03399_abstract.tex," Recent data-driven approaches to scene interpretation predominantly pose inference as an end-to-end black-box mapping, commonly performed by a Convolutional Neural Network (CNN). However, decades of work on perceptual organization in both human and machine vision suggests that there are often intermediate representations that are intrinsic to an inference task, and which provide essential structure to improve generalization. In this work, we explore an approach for injecting prior domain structure into neural network training by supervising hidden layers of a CNN with intermediate concepts that normally are not observed in practice. We formulate a probabilistic framework which formalizes these notions and predicts improved generalization via this deep supervision method. One advantage of this approach is that we are able to train only from synthetic CAD renderings of cluttered scenes, where concept values can be extracted, but apply the results to real images. Our implementation achieves the state-of-the-art performance of 2D/3D keypoint localization and image classification on real image benchmarks, including KITTI, PASCAL VOC, PASCAL3D+, IKEA, and CIFAR100. We provide additional evidence that our approach outperforms alternative forms of supervision, such as multi-task networks.  % A complete scene interpretation pipeline needs a nuanced parsing of 3D object structure and pose as its backbone. The revival of data-driven approaches for visual recognition has brought us closer to solving this problem, yet these methods are limited by scarcity of real labeled data. We present a novel approach which infuses domain priors into neural network training for robust generalization. Our key innovation is to deeply supervise hidden layers of a CNN through intermediate concepts, teaching it to recover a sequence of intermediate milestones for final task prediction. We formulate a probabilistic framework which formalizes this notion and predicts its improved generalization. Our method, only trained on synthetic CAD renders of cluttered scenes, achieves state-of-the-art performance on real image benchmarks, including KITTI, PASCAL VOC, PASCAL3D+, IKEA, and CIFAR100 for 2D and 3D keypoint localization, instance segmentation, and image classification. We obtain further validation of our approach by outperforming ablative configurations including conventional multi-task supervision and alternate sequences of intermediate supervision. "
1801_05526_PP-Article.tex,"\abstract{The High Altitude Water Cherenkov (HAWC) observatory is a ground-based air-shower detector designed to study the TeV gamma and cosmic ray windows. The observatory is composed of a densely packed array of $300$ water Cherenkov tanks, $4.5$ m deep and $7.3$ diameter with $4$ photomultipliers (PMT) each, distributed on a $22,000 m^2$ surface. The instrument registers the number of hit PMT's as well as the  timing information and the total charge seen by the photomultipliers during the shower event. From the analysis of these data, shower observables such as the arrival direction, the core position at ground, the age and the primary energy are estimated, from which the energy spectrum of cosmic rays and its composition can be studied. In this work, we will describe the methodologies of HAWC cosmic ray analyses, including the Bayesian spectral unfolding procedure used to determine the all-particle and the light component energy spectra of cosmic rays. We will see that the distribution of the shower age vs the fraction of hit PMT's contains information about the composition of cosmic rays.}"
1801_03167_main.tex," We present extensive ultraviolet (UV) and optical photometry, as well as dense optical spectroscopy for type II Plateau (IIP) supernova \sn \ that exploded in the nearby ($\sim$ 15 Mpc) spiral galaxy \host. The observations span the period from 2 to 180 days after the explosion; in particular, the Swift UV data probably captured the signature of shock breakout associated with the explosion of \sn. It shows very strong UV emission during the first week after explosion, with contribution of $\sim$ 20 -- 30 \% to the bolometric luminosity (versus $\lesssim$ 15 \% for normal SNe IIP). Moreover, we found that this supernova has an unusually long rise time of about 12.6 $\pm$ 0.5 days in the $R$ band (versus $\sim$ 7.0 days for typical SNe IIP). The optical light curves and spectral evolution are quite similar to the fast-declining type IIP object SN 2013ej, except that \sn \ has a relatively brighter tail. Based on the evolution of photospheric temperature as inferred from the $Swift$ data in the early phase, we derive that the progenitor of \sn \ has a radius of about 930 $\pm$ 70 \rsun. This large-size star is expected to be a red supergiant star with an initial mass of $\gtrsim$ 19 -- 20 M $_{\odot}$ based on the mass $--$ radius relation of the Galactic red supergiants, and it represents one of the most largest and massive progenitors found for SNe IIP. "
1801_01158_U1Redux2.tex," Despite the seeming simplicity of the theory, calculating (and even defining) entanglement entropy for the Maxwell theory of a $U(1)$ gauge field in (3+1) dimensions has been the subject of controversy. It is generally accepted that the ground state entanglement entropy for a region of linear size $L$ behaves as an area law with a subleading logarithm, $S = \alpha L^2 -\gamma \log L$ . While the logarithmic coefficient $\gamma$ is believed to be universal, there has been disagreement about its precise value. After carefully accounting for subtle boundary corrections, multiple analyses in the high energy literature have converged on an answer related to the conformal trace anomaly, which is only sensitive to the local curvature of the partition. In contrast, a condensed matter treatment of the problem yielded a topological contribution which is not captured by the conformal field theory calculation. In this perspective piece, we review aspects of the various calculations and discuss the resolution of the discrepancy, emphasizing the important role played by charged states (the ``extended Hilbert space"") in defining entanglement for a gauge theory. While the trace anomaly result is sufficient for a strictly pure gauge field, coupling the gauge field to dynamical charges of mass $m$ gives a topological contribution to $\gamma$ which survives even in the $m\rightarrow\infty$ limit. For many situations, the topological contribution from dynamical charges is physically meaningful and should be taken into account. We also comment on other common issues of entanglement in gauge theories, such as entanglement distillation, algebraic definitions of entanglement, and gauge-fixing procedures. "
1801_06868_draft.tex," We experimentally demonstrate the light-controlled assembly of active colloidal molecules from a suspension of two species of passive microspheres.When light is shone on the sample, the active molecules form and acquire motility through non-reciprocal interactions between their passive components. As their size grows, they feature a complex array of behaviors, becoming propellers, spinners and rotators. Their shape and functionality can be tuned by applying periodic illumination. We also provide a theoretical model allowing to predict the complete table of emerging active molecules and their properties in quantitative agreement with the experiments. "
1801_10413_HP_arxiv.tex," 		A variety $X/k$ is said to have the Hilbert Property if $X(k)$ is not thin. We shall describe some examples of varieties, for which the Hilbert Property is a new result. 		 		 We give a criterion for determining when the Hilbert Property for a variety $X$ implies the Hilbert Property for quotients $X/G$ of the variety by an action of a finite group. In the case of linear actions of the group $G$ , this gives examples of (non-rational) unirational varieties with the Hilbert Property, providing positive examples to a conjecture by Colliot-Thélène and Sansuc. 		 		 We focus then on the study of the Hilbert Property for K3 surfaces that have two elliptic fibrations, in particular on diagonal quartic surfaces, i.e. varieties of the form $ax^4+by^4+cz^4+dw^4=0$ . We then show, through an explicit application, how one may use the criterion above to provide other examples of K3 surfaces with the Hilbert Property. Since the Hilbert Property is related to an abudance of rational points, K3 surfaces should (conjecturally) represent a limiting case in dimension 2. 		 %		 Rational Points \and Cubic and quartic equations \and Hilbert Property \and Elliptic Fibrations 		 % PACS code1 \and PACS code2 \and more %		  14G05 \and 11D25 \and 14G99 	"
1801_09603_BDF2WassersteinPaper.tex," We prove convergence of a variational formulation of the BDF2 method applied to the non-linear Fokker-Planck equation. Our approach is inspired by the JKO-method and exploits the differential structure of the underlying $L^2$ -Wasserstein space. The technique presented here extends and strengthens the results of our own recent work on the BDF2 method for general metric gradient flows in the special case of the non-linear Fokker-Planck equation: firstly, we do not require uniform semi-convexity of the augmented energy functional; secondly, we prove strong instead of merely weak convergence of the time-discrete approximations; thirdly, we directly prove without using the abstract theory of curves of maximal slope that the obtained limit curve is a weak solution of the non-linear Fokker-Planck equation. "
1801_05722_Degree-One.tex," Let $K$ denote a knot inside the homology sphere $Y$ and  $K'$ denote a knot inside a homology sphere $L$ -space. Let  $X=Y(K,K')$ denote the 3-manifold obtained by splicing the complements of $K$ and $K'$ . We show that  $\mathrm{HF}(X)) \mathrm{HF}(Y))$ . "
1801_05089_bare_jrnl.tex," We propose to use second order Reed-Muller (RM) sequence for user identification in 5G grant-free access. The benefits of RM sequences mainly lie in two folds, (i) support of much larger user space, hence lower collision probability and (ii) lower detection complexity. These two features are essential to meet the massive connectivity ( $10^7$ links/km $^2$ ), ultra-reliable and low-latency requirements in 5G, e.g., one-shot transmission ( $\leq 1$ ms) with $-4$ packet error rate. However, the non-orthogonality introduced during sequence space expansion leads to worse detection performance. In this paper, we propose a noise-resilient detection algorithm along with a layered sequence construction to meet the harsh requirements. Link-level simulations in both narrow-band and OFDM-based scenarios show that RM sequences are suitable for 5G.% This work was supported in part by National Natural Science Foundation of China (No. 61401388) and the China Postdoctoral Science Foundation Funded Project (No. 2014M551736). "
1801_03962_social_spatial_article_EPJ_arxiv.tex," % abstract According to personality psychology, personality traits determine many aspects of human behaviour. However, validating this insight in large groups has been challenging so far, due to the scarcity of multi-channel data. Here, we focus on the relationship between mobility and social behaviour by analysing two high-resolution longitudinal datasets collecting trajectories and mobile phone interactions of $\sim 1000$ individuals. We show that there is a connection between the way in which individuals explore new resources and exploit known assets in the social and spatial spheres. We point out that different individuals balance the exploration-exploitation trade-off in different ways and we explain part of the variability in the data by the big five personality traits. We find that, in both realms, extraversion correlates with an individual's attitude towards exploration and routine diversity, while neuroticism and openness account for the tendency to evolve routine over long time-scales. We find no evidence for the existence of classes of individuals across the spatio-social domains. Our results bridge the fields of human geography, sociology and personality psychology and can help improve current models of mobility and tie formation. "
1801_00651_MNRAS_stx2398.tex," The escape dynamics of the stars in a barred galaxy composed of a spherically symmetric central nucleus, a bar, a flat thin disk and a dark matter halo component is investigated by using a realistic three degrees of freedom (3-dof) dynamical model. Modern colour-coded diagrams are used for distinguishing between bounded and escaping motion. In addition, the smaller alignment index (SALI) method is deployed for determining the regular, sticky or chaotic nature of bounded orbits. We reveal the basins of escape corresponding to the escape through the two symmetrical escape channels around the Lagrange points $L_2$ and $L_3$ and also we relate them with the corresponding distribution of the escape times of the orbits. Furthermore, we demonstrate how the stable manifolds, around the index-1 saddle points, accurately define the fractal basin boundaries observed in the colour-coded diagrams. The development scenario of the fundamental vertical Lyapunov periodic orbit is thoroughly explored for obtaining a more complete view of the unfolding of the singular behaviour of the dynamics at the cusp values of the parameters. Finally, we examine how the combination of the most important parameters of the bar (such as the semi-major axis and the angular velocity) influences the observed stellar structures (rings and spirals) which are formed by escaping stars guided by the invariant manifolds near the saddle points. "
1801_03357.tex," For a noetherian ring $A$ and its idempotent $e$ , Chen gave a sufficient condition so that a natural functor $G:\mod A\to \mod eAe$ induces a singular equivalence between $A$ and $eAe$ . The aim of this paper is to give a categorical version of Chen's theorem. As an application, we show that there exists a singular equivalence arising from a certain class of cotorsion pairs in $\mod\Lambda$ over a finite dimensional algebra $\Lambda$ . Finally we give a short proof of the following Matsui and Takahashi's theorem: Let $A$ be an Iwanaga-Gorenstein ring. It was proved that the projectively stable module category $\modA$ and its full subcategory $\CM(A)$ consisting of Gorenstein projective modules are singularly equivalent. "
1801_03055_DeconvolvingRNA-arXiv.tex," The structure of an RNA sequence encodes information about its biological function. A sequence is typically predicted to fold to a single minimum free energy conformation. But, an increasing number of RNA molecules are now known to fold into multiple stable structures. Discrete optimization methods are commonly used to predict foldings, and adding experimental data as auxiliary information improves prediction accuracy when there is a single dominant conformation. In this paper, we analyze the outputs of existing structural prediction models when they receive auxiliary data derived from a mixture of structures. Under a binary model of auxiliary data, we find that current structural prediction methods typically favor distributions with one dominant structure, and hence cannot guarantee accurate reconstruction of multimodal distributions. Additionally, we analyze empirical distributions of auxiliary data used in current prediction models. We show that even when the structures in a distribution are known in advance, it is difficult to determine the weightings of the structures using auxiliary data. RNA secondary structure \and thermodynamic optimization with auxiliary data \and method of moments estimators % 92D20 \and 05A15 \and 62P10 "
1801_05477_domain_walls.tex," In ordinary QCD with light, degenerate, fundamental flavors, $CP$ symmetry is spontaneously broken at $\theta=\pi$ , and domain wall solutions connecting the vacua can be constructed in chiral perturbation theory. In some cases the breaking of $CP$ saturates an 't Hooft anomaly, and anomaly inflow requires nontrivial massless excitations on the domain walls. Analogously, $CP$ can be spontaneously broken in supersymmetric QCD with light flavors and small soft breaking parameters. We study $CP$ breaking and domain walls in softly broken SQCD with $N_f<N$ flavors. Relative to ordinary QCD, the supersymmetric case contains an extra light field, the $\etap$ , which has interesting effects on the structure of the walls. Vanishing of the $CP$ anomaly is associated with the existence of multiple domain wall trajectories through field space, including walls which support no nontrivial massless excitations. In cases with an anomaly such walls are forbidden, and their absence in the relevant SQCD theories can be seen directly from the geometry of the low energy field space. In the case $N_f=N-1$ , multiple approximately-BPS walls connect the vacua. Corrections to their tensions can be computed at leading order in the soft breaking parameters, producing a phase diagram for the stable wall trajectory. We also comment on domain walls in the similar case of QCD with an adjoint and fundamental flavors, and on the impact of adding an axion in this theory. "
1801_05502_fermi_transients.tex," The Fermi LAT has detected numerous transient gamma-ray sources near the Galactic plane, several of which have been shown to be located within our Galaxy. We present an analysis of LAT Pass 8 data of seven previously reported, but still unidentified transient gamma-ray sources located within $10^\circ$ of the Galactic plane. We detect significant gamma-ray emission lasting several days for three of these sources: Fermi J0035+6131, Fermi J0905-3527, and Fermi J0910-5041. However, we were not able to detect the increase in gamma-ray emission that has previously been reported in the other four cases. We also review available multiwavelength data for the transients and discuss potential counterparts. "
1801_00194_arxiv-dc09.tex," We consider deterministic distributed broadcasting on multiple access channels in the framework of adversarial queuing. Packets are injected dynamically by an adversary that is constrained by the injection rate and the number of packets that may be injected simultaneously; the latter we call burstiness. An algorithm is stable when the number of packets in queues at the stations stays bounded. % The maximum injection rate that an algorithm can handle in a stable manner is called the throughput of the algorithm. We consider adversaries of injection rate~ $1$ , that is, of one packet per round, to address the question if the maximum throughput~ $1$ can be achieved, and if so then with what quality of service. We develop an algorithm that achieves throughput~ $1$ for any number of stations against leaky-bucket adversaries. The algorithm has $burstiness)$ packets queued simultaneously at any time, where $n$ is the number of stations; this upper bound is proved to be best possible. % An algorithm is called fair when each packet is eventually broadcast. We show that no algorithm can be both stable and fair for a system of at least two stations against leaky-bucket adversaries. % We study in detail small systems of exactly two and three stations against window adversaries to exhibit differences in quality of broadcast among classes of algorithms. An algorithm is said to have fair latency if the waiting time of packets is $burstiness)$ . For two stations, we show that fair latency can be achieved by a full sensing algorithm, while there is no stable acknowledgment based algorithm. For three stations, we show that fair latency can be achieved by a general algorithm, while no full sensing algorithm can be stable. % Finally, we show that algorithms that either are fair or do not have the queue sizes affect the order of transmissions cannot be stable in systems of at least four stations against window adversaries.  \vfill  \noindent Keywords: multiple access channel, adversarial queuing, distributed broadcasting, deterministic algorithm, stability, throughput, packet latency. "
1801_00481_papert_V3.tex, Lack of fast and strong actuators to drive microsystems is well recognized. Electrochemical actuators are considered attractive for many applications but they have long response time (minutes) due to slow gas termination. Here an electrochemical actuator is presented for which the response time can be as short as $1\:$ ms. The alternating polarity water electrolysis is used to drive the device. In this process only nanobubbles are formed. The gas in nanobubbles can be terminated fast due to surface assisted reaction between hydrogen and oxygen that happens at room temperature. The working chamber of the actuator contains concentric titanium electrodes; it has a diameter of $500\:\mu$ m and a height of $8\:\mu$ m. The chamber is sealed by a polydimethylsiloxane (PDMS) membrane of $30\:\mu$ m thick. The device is characterized by an interferometer and a fast camera. Cyclic operation at frequency up to $667\:$ Hz with a stroke of about 30 \% of the chamber volume is demonstrated. The cycles repeat themselves with high precision providing the volume strokes in picoliter range. Controlled explosions in the chamber can push the membrane up to $90\:\mu$ m.
1801_04628_ij1801.tex," We perform the stability analysis of Schwarzschild-AdS (SAdS) black hole in the Einstein-Ricci cubic gravity. It shows that the Ricci tensor perturbations exhibit unstable modes for small black holes. We call this the mass-induced instability of SAdS black hole because the instability of small black holes arises from the massiveness in the linearized Einstein-Ricci cubic gravity, but not a feature of higher-order derivative theory giving ghost states. Also, we point out that the correlated stability conjecture holds for the SAdS black hole by computing the Wald entropy of SAdS black hole in Einstein-Ricci cubic gravity. "
1801_09689_32324.tex,"\abstract{We observed a sample of 90 red giant branch (RGB) stars in NGC~2808 using FLAMES/GIRAFFE and the high resolution grating with the set up HR21. These stars have previous accurate atmospheric parameters and abundances of light elements. We derived aluminium abundances for them from the strong doublet Al {\sc i} 8772-8773~\AA\[Al/Fe] as in previous works of our group. In addition, we were able to estimate the relative CN abundances for 89 of the stars from the strength of a large number of CN features. When adding self consistent abundances from previous UVES spectra analysed by our team, we gathered ratios for a total of 108 RGB stars in NGC~2808. The full dataset of proton-capture elements is used to explore in details the five spectroscopically detected discrete components in this globular cluster. We found that different classes of polluters are required to reproduce the (anti)-correlations among all proton-capture elements in the populations P2, I1, and I2 with intermediate composition. This is in agreement with the detection of lithium in lower RGB second generation stars, requiring at least two kind of polluters. To have chemically homogeneous populations the best subdivision of our sample is into six components, as derived from statistical cluster analysis. By comparing different diagrams [element/Fe] vs [element/Fe] we show for the first time that a simple dilution model is not able to reproduce all the sub-populations in this cluster. Polluters of different masses are required. NGC~2808 is confirmed to be a tough challenge to any scenario for globular cluster formation. }"
1801_08842.tex, The class of self-conjugate-reciprocal irreducible monic (SCRIM) polynomials over finite fields are studied. Necessary and sufficient conditions for monic irreducible polynomials to be SCRIM are given. The number of SCRIM polynomials of a given degree are also determined.
1801_00363_arxiv_version.tex," We present a non-trivial correlation between the enhancement of the Higgs-fermion couplings and the Higgs pair production cross section in two Higgs doublet models with a flavour symmetry. This symmetry suppresses flavour-changing neutral couplings of the Higgs boson and allows for a partial explanation of the hierarchy in the Yukawa sector. After taking into account the constraints from electroweak precision measurements, Higgs coupling strength measurements, and unitarity and perturbativity bounds, we identify an interesting region of parameter space leading to enhanced Yukawa couplings as well as enhanced di-Higgs gluon fusion production at the LHC reach. This effect is visible in both the resonant and non-resonant contributions to the Higgs pair production cross section. We encourage dedicated searches based on differential distributions as a novel way to indirectly probe enhanced Higgs couplings to light fermions.  "
1801_03569_MRI-ball10.tex," The Magnetorotational Instability (MRI) has long been considered a plausibly ubiquitous mechanism to destabilize Keplerian flows, transport angular momentum, and facilitate fast accretion in astrophysical objects. But heretofore, experimental validation has been lacking. We report an unambiguous laboratory demonstration of the spring-mass analogue to the MRI by comparing motion of a spring-tethered ball within different rotating flows. As predicted, efficient outward angular momentum transport manifests only for cases with a weak spring and quasi-Keperian flow. "
1801_03887.tex," We prove two results about width of words in $Z)$ . The first is that, for every $n \ge 3$ , there is a constant $C(n)$ such that the width of any word in $Z)$ is less than $C(n)$ . The second result is that, for any word $w$ , if $n$ is big enough, the width of $w$ in $Z)$ is at most 1737. %We prove that, for every $d \ge 1$ and every non-trivial element $w$ in the free group $F_d$ on $d$ generators, there exists a constant $N_w$ such that if $n \ge N_w$ then $w(1937=\SL(n,\Z)$ , where $$w(SL(n,g,g^{-1 Hom(F_d,\SL(n,\Z)). \  \rho(w)=g\}.$$ "
1801_07784_TargetZone_Skor.tex," We consider a stochastic game between a trader and the central bank on target zone markets. In this type of markets the price process is modeled as a diffusion which is reflected at one or more barriers. Such models arise when a currency exchange rate is kept above a certain threshold due to central bank intervention. We consider a trader who wishes to liquidate a large amount of currency, where for whom prices are optimal at the barrier. The central bank, who wishes to keep the currency exchange rate above %a certain this barrier, therefore needs to buy its own currency. The permanent price impact, which is created by the transactions of both sides, turns the optimal trading problems of the trader and the central bank into coupled singular control problems, where the common singularity arises from a local time along a random curve. We first solve the central bank's control problem by means of the Skorokhod map and then derive the trader's optimal strategy by solving a sequence of approximated control problems, thus establishing a Stackelberg equilibrium in our model. "
1801_01871_main.tex,"We devise a new user-friendly tool interfaced with the Boltzmann code \CLASS~to deal with any kind of exotic electromagnetic energy injection in the universe and its impact on anisotropies of the Cosmic Microwave Background. It makes use of the results from standard electromagnetic cascade calculations develop in the context of WIMP annihilation, generalized to incorporate any injection history. We first validate it on a specific WIMP scenario, the Higgs Portal model, confirming that the standard effective on-the-spot treatment is accurate enough. We then analyze the more involved example of evaporating Primordial Black Holes (PBHs) with masses in the range $[3\times10^{13,516]$g, for which the standard approximations break down. We derive robust CMB bounds on the relic density of evaporating PBHs, ruling out the possibility for PBHs with a monochromatic distribution of masses in the range $[313,2.516]$g to represent all of the Dark Matter in our Universe. Remarkably, we confirm with an accurate study that the CMB bounds are several orders of magnitude stronger than those from the galactic gamma-ray background in the range $[313,314]$g. A future CMB experiment like CORE+, or an experiment attempting at measuring the 21 cm signal from the Dark Ages could greatly improve the sensitivity to these models.}"
1801_08309.tex," In this paper, motivated by recent important works due to Frank-Lewin-Lieb-Seiringer FLLS and Frank-Sabin frank-sabin-1 , we study the Strichartz inequality on torus with the orthonormal system input and obtain sharp estimates in certain sense. An application of the inequality shows the well-posedness to the periodic Hartree equation describing the infinitely many quantum particles with the power type interaction.   "
1801_06943_curvature_and_augmentation13__arxiv_submission_.tex," Given a graded module over a commutative ring, we define a dg-Lie algebra whose Maurer-Cartan elements are the strictly unital \Ai-algebra structures on that module. We use this to generalize Positselski's result that a curvature term on the bar construction compensates for a lack of augmentation, from a field to arbitrary commutative base ring. We also use this to show that the reduced Hochschild cochains control the strictly unital deformation functor. We motivate these results by giving a full development of the deformation theory of a nonunital \Ai-algebra. "
1801_01359_corvar19.tex," When performing global sensitivity analysis (GSA), it is often assumed, for the sake of simplicity, for lack of information, or for sheer expediency, that uncertain variables in the model are independent. It is intuitively clear--and easily confirmed through simple examples--that applying a GSA method designed for independent variables to a set of correlated variables generally leads to results that hard to interpret, at best. We generalize the probabilistic framework for GSA pioneered by Sobol' to problems with correlated variables; this is done by reformulating his indices in terms of approximation errors rather than variance analysis. The implementation of the approach and its computational complexity are discussed and illustrated on synthetic examples. "
1801_06096_BayesUQ_v2.tex,"  \item[Background:]  Being able to rigorously quantify the uncertainties in reaction models is crucial to moving this field forward. Even though Bayesian methods are becoming increasingly popular in nuclear theory, they are yet to be implemented and applied in reaction theory problems.  \item[Purpose:]  The purpose of this work is to investigate, using Bayesian methods, the uncertainties in the optical potentials generated from fits to elastic scattering data and the subsequent uncertainties in the transfer predictions. We also study the differences in two reaction models where the parameters are constrained in a similar manner, as well as the impact of reducing the experimental error bars on the data used to constrain the parameters. \item[Method:]  We use Bayes' Theorem combined with a Markov Chain Monte Carlo to determine posterior distributions for the parameters of the optical model, constrained by neutron-, proton-, and/or deuteron-target elastic scattering. These potentials are then used to predict transfer cross sections within the adiabatic wave approximation or the distorted-wave Born approximation.  \item[Results:]  We study a number of reactions involving deuteron projectiles with energies in the range of $10-25$ MeV/u on targets with mass $A=48-208$ . The case of  $^{48}$ Ca(d,p) $^{49}$ Ca transfer to the ground state is described in detail. A comparative study of the effect of the size of experimental errors is also performed. Five transfer reactions are studied, and their results compiled in order to systematically identify trends. \item[Conclusions:]  Uncertainties in transfer cross sections can vary significantly (25-100 \%) depending on the reaction.  While these uncertainties are reduced when smaller experimental error bars are used to constrain the potentials, this reduction is not trivially related to the error reduction. We also find smaller uncertainties when using the adiabatic formulation than when using distorted-wave Born approximation.   "
1801_09905_SOI_NW.tex," We use $kp$ theory to estimate the Rashba spin-orbit coupling (SOC) in large semiconductor nanowires. We specifically investigate GaAs- and InSb-based devices with different gate configurations to control symmetry and localization of the electron charge density. We explore gate-controlled SOC for wires of different size and doping, and we show that in high carrier density SOC has a non-linear electric field susceptibility, due to large reshaping of the quantum states. We analyze recent experiments with InSb nanowires in light of our calculations. Good agreement is found with SOC coefficients reported in Phys.~Rev.~B 91 , 201413(R) (2015), but not with the much larger values reported in Nat~Commun., 8 , 478 (2017). We discuss possible origins of this discrepancy. "
1801_01649_main.tex," Computing the partition function $Z$ of a discrete graphical model is a fundamental inference challenge. %the most important statistical %inference task. Since this is computationally intractable, variational approximations %methods are often used %to resolve the issue in practice. Recently, so-called gauge transformations were used to improve variational %methods to obtain tighter lower bounds on $Z$ . In this paper, we propose a new gauge-variational approach, termed WMBE-G, which combines gauge transformations %approach and with the weighted mini-bucket elimination (WMBE) method. WMBE-G can provide both upper and lower bounds on $Z$ , and is easier to optimize than the prior gauge-variational algorithm. %We also suggest some analytical characterization and %More importantly, We show that WMBE-G strictly improves the earlier WMBE approximation for symmetric models including Ising models with no magnetic field. Our experimental results demonstrate the effectiveness of WMBE-G even for generic, nonsymmetric models. %it has superior performance in comparison with %outperforms other state of the art algorithms, including %WMBE, %even for generic, non-symmetric models. %, including WMBE. % {blue ... shall we call the new algorithm(s) Variarional Gauge Holder algorithm(s)? ... inventing a name would be useful ...} "
1801_10484_1_Cache-Aided_NOMA_20180121.tex," In this paper, we propose a cache-aided non-orthogonal multiple access (NOMA) scheme for spectrally efficient downlink transmission in the fifth-generation (5G) cellular networks. The proposed scheme not only reaps the benefits associated with caching and NOMA, but also exploits the data cached at the users for interference cancellation. As a consequence, caching can help to reduce the residual interference power, making multiple decoding orders at the users feasible. The resulting flexibility in decoding can be exploited for realizing additional performance gains. We characterize the achievable rate region of cache-aided NOMA and derive the Pareto optimal rate tuples forming the boundary of the rate region. Moreover, we optimize cache-aided NOMA for minimization of the time required for video file delivery. The optimal decoding order and the optimal transmit power and rate allocation are derived as functions of the cache status, the file sizes, and the channel conditions. Our simulation results confirm that compared to several baseline schemes, the proposed cache-aided NOMA scheme significantly expands the achievable rate region and increases the sum rate for downlink transmission, which translates into substantially reduced file delivery times. "
1801_04610.tex," The momentum operator for a spin-less particle when confined to a 2D surface embedded into 3D space acquires a geometrical component proportional to the mean curvature that renders it Hermitian. As a consequence, the quantum force operator for a particle confined to spherical and cylindrical surfaces, and free otherwise, derived by applying the Heisenberg equation of motion is found to have an apparently no-radial component in addition to the standard classical radial centripetal force. This component which renders the force operator Hermitian is shown to be essential for the vanishing of the torque the force exerts on the particle and so for the conservation of orbital angular momentum and energy. It is demonstrated that the total force is in fact radial as should be the case for a torque-less one and so can be identified as the quantum centripetal force. "
1801_08167_brogaard.tex," %This is a simple template for authors to write new MNRAS papers. %The abstract should briefly describe the aims, methods, and main results of the paper. %It should be a single paragraph not more than 250 words (200 words for Letters). %No references should appear in the abstract. We aim to establish and improve the accuracy level of asteroseismic estimates of mass, radius, and age of giant stars. This can be achieved by measuring independent, accurate, and precise masses, radii, effective temperatures and metallicities of long period eclipsing binary stars with a red giant component that displays solar-like oscillations. %We measured precise properties of the three eclipsing binary systems KIC \,7037405, KIC \,9540226, and KIC \,9970396, finding for the giant components their masses to a precision of $1.7\%, 2.8\%$ , and $1.3\%$ , and their radii to a precision of $0.7\%, 1.2\%$ , and $0.9\%$ . Then, using log $g$ with the disentangled spectra we also determined $T_{\rm eff}$ and [Fe/H] and estimated the ages of the systems to be $5.3\pm0.5$ , $3.1\pm0.6$ , and $4.8\pm0.5$ Gyr for the adopted stellar model physics. We measured precise properties of the three eclipsing binary systems KIC \,7037405, KIC \,9540226, and KIC \,9970396 and estimated their ages be $5.3\pm0.5$ , $3.1\pm0.6$ , and $4.8\pm0.5$ Gyr. The measurements of the giant stars were compared to corresponding measurements of mass, radius, and age using asteroseismic scaling relations and grid modeling. We found that asteroseismic scaling relations without corrections to $\Delta \nu$ systematically overestimate the masses of the three red giants by 11.7 \%, 13.7 \%, and 18.9 \Delta \nu$ according to Rodrigues2017 , we reached general agreement between dynamical and asteroseismic mass estimates, and no indications of systematic differences at the precision level of the asteroseismic measurements. The larger sample investigated by Gaulme2016 showed a much more complicated situation, where some stars show agreement between the dynamical and corrected asteroseismic measures while others suggest significant overestimates of the asteroseismic measures. We found no simple explanation for this, but indications of several potential problems, some theoretical, others observational. Therefore, an extension of the present precision study to a larger sample of eclipsing systems is crucial for establishing and improving the accuracy of asteroseismology of giant stars.    "
1801_03213_sigma-fluc.tex," The chiral order-parameter $\sigma$ field and its higher-order cumulants of fluctuations are calculated within the functional renormalization group approach. The influence of the glue dynamics on the fluctuations of $\sigma$ field is investigated, and we find that the $\sigma$ -field fluctuations are weakly affected by the glue dynamics. This is in sharp contrast to the baryon number fluctuations, which are sensitive to the glue dynamics and involve information of the color confinement. Implications of our calculated results on theoretical and experimental efforts to search for the QCD critical ending point are discussed. "
1801_02879_paper_new_joint_.tex," In high-quality two-dimensional (2D) materials the mean free paths of phonons and electrons relative  to all mechanisms of scattering can be much greater than a size of a sample. Thereby the most  intensive type of particle scattering is their collisions  with sample edges. For such ballistic regime, we study the flow   of classical interacting 2D particles in a long narrow sample. The main part of the ballistic conductance, related to the scattering of particles on the sample edges, diverges logarithmically with the sample width decrease. This divergency is limited by scattering or by a finite sample length.  We calculate two types  of the corrections to the main part of the ballistic conductance: the positive {\em hydrodynamic} correction due to the inter-particle scattering conserving momentum and the negative {\em Ohmic } correction due to the scattering not conserving momentum. We also study the effect of weak magnetic field on the electronic ballistic conductance. The resulting magnetoresistance is negative and independent of temperature for not very long samples. Our analysis shows that, possibly, such magnetoresistance was observed in recent experiments  on the high-mobility  GaAs quantum wells.  72.20.-i,  73.63.Hs, 72.80.Vp, 73.43.Qt  "
1801_08925_paper.tex," Predicting attention is a popular topic at the   intersection of human and computer vision, but video   saliency prediction has only recently begun to benefit from   deep learning-based approaches. Even though most of the available   video-based saliency data sets and models claim to target human observers'   fixations, they fail to   differentiate them from smooth pursuit (SP), a major eye movement type   that is unique to perception of dynamic scenes.   In this work, we aim to make this distinction explicit, to which   end we (i) use both algorithmic and manual annotations   of SP traces and other eye movements for two well-established video saliency data sets,   (ii) train Slicing Convolutional Neural Networks (S-CNN) for   saliency prediction on either   fixation- or SP-salient locations, and (iii) evaluate ours and over 20   popular published saliency models on the two annotated data sets   for predicting both SP and fixations, as well as   on another data set of human fixations.    Our proposed model, trained on an independent set of videos, outperforms the   state-of-the-art saliency models   in the task of SP prediction on all considered data sets. Moreover, this model also demonstrates superior   performance in the prediction of ``classical'' fixation-based saliency.   Our results emphasize the importance of selectively approaching training set construction for attention modelling. "
1801_09013_paper1.6.tex," Hassett spaces are moduli spaces of weighted stable pointed curves. In this work, we consider such spaces of curves of genus $0$ with weights all $1{2}$ . These spaces are interesting as they are isomorphic to $M_{0,n}$ but have different universal families and different intersection theory. We develop a closed formula for top intersections of $\psi$ -classes on such spaces. Then we encode this formula in a generating function obtained by applying a differential operator to the Witten-potential. "
1801_06910_Variable_coefficient_Wolff_inequalities.tex," The sharp Wolff-type decoupling estimates of Bourgain--Demeter are extended to the variable coefficient setting. These results are applied to obtain new sharp local smoothing estimates for wave equations on compact Riemannian manifolds, away from the endpoint regularity exponent. More generally, local smoothing estimates are established for a natural class of Fourier integral operators; at this level of generality the results are sharp in odd dimensions, both in terms of the regularity exponent and the Lebesgue exponent. "
1801_07296.tex," Let $(G, P)$ be an abelian, lattice ordered group and let $X$ be a compactly aligned, $\phi$ -injective product system over $P$ . We show that the C*-envelope of the Nica tensor algebra $N \cT^+_X$ is the Cuntz-Nica-Pimsner algebra $\cN \cO_X$ as defined by Sims and Yeend. We give several applications of this result. First we resolve a problem posed by Skalski and Zacharias on dilating isometric representations of product systems to unitary representations. As a second application we characterize the $\ca$ -envelope of the tensor algebra of a finitely aligned higher-rank graph. An analogous result holds for the $\ca$ -envelope of the tensor algebra of a compactly aligned topological $k$ -graph. As a third application we show that the Hao-Ng isomorphism problem for generalized gauge actions of discrete groups on $\ca$ -algebras of product systems has an affirmative answer in many cases, generalizing recent results of Bedos, Quigg, Kaliszewski and Robertson and of the second author. As a final application, we show the existence of a co-universal $\ca$ -algebra for injective, gauge compatible, Nica-covariant representations of a compactly aligned product system over an abelian, lattice ordered group. This is done without the assumption of $\phi$ -injectivity and we therefore resolve in that case a problem that was left open in the work of Carlsen, Larsen, Sims and Vittadello. "
1801_02813_draft11.tex," Abstract Excitation energy transfer (EET) is one of the most important processes in both natural and artificial chemical systems including, for example, photosynthetic complexes and organic solar cells. The EET rate, however, is strongly suppressed when there is a large difference in the excitation energy between the donor and acceptor molecules. Here, we demonstrate both analytically and numerically that the EET rate can be greatly enhanced by periodically modulating the excitation energy difference. The enhancement of EET by using this Floquet engineering, in which the system's Hamiltonian is made periodically time-dependent, turns out to be efficient even in the presence of strong fluctuations and dissipations induced by the coupling with a huge number of dynamic degrees of freedom in the surrounding molecular environments. As an effect of the environment on the Floquet engineering of EET, the optimal driving frequency is found to depend on the relative magnitudes of the system and environment's characteristic time scales with an observed frequency shift when moving from the limit of slow environmental fluctuations (inhomogeneous broadening limit) to that of fast fluctuations (homogeneous broadening limit). "
1801_06025_pnp_npn.tex," This work reports an approach to study complementary pairs of bipolar junction transistors, often used in push-pull circuits typically found at the output stages of operational amplifiers. After the data is acquired and pre-processed, an Early modeling approach is applied to estimate the two respective parameters (the Early voltage $V_a$ and the proportionality parameter $s$ ). A voting procedure, inspired on the Hough transform image analysis method, is adopted to improve the identification of $V_a$ . Analytical relationships are derived between the traditional parameters current gain ( $\beta$ ) and output resistance ( $R_o$ ) and the two Early parameters. It is shown that $\beta$ tends to increase with $s$ for fixed $V_a$ , while $R_o$ depends only on $V_a$ , varying linearly with this parameter. Several interesting results are obtained with respect to 7 pairs of complementary BJTs, each represented by 10 samples. First, we have that the considered BJTs occupy a restricted band along the Early parameter space, and also that the NPN and PNP groups are mostly segregated into two respective regions in this space. In addition, PNP devices tended to present an intrinsically larger parameter variation. The NPN group tended to have higher $V_a$  magnitude and smaller $s$ than PNP devices. NPN transistors yielded comparable $\beta$ and larger $R_o$ than PNP transistors. A pattern recognition method was employed to obtain a linear separatrix between the NPN and PNP groups in the Early space and the respective average parameters were used to estimate respective prototype devices. Two complementary pairs of the real-world BJTs with large and small parameters differences were used in three configurations of push pull circuits, and the respective total harmonic distortions were measured and discussed, indicating a definite influence of parameter matching on the results. "
1801_04298_cstruct_v1.tex," The objective of this work is to investigate the fundamental challenges encountered in modelling and simulation of turbulent flows driven by spatially-developing coherent structures. Scale-Resolving Simulations (SRS's) of practical interest are expressly intended for efficiently computing such flows by resolving only the most important features of the coherent structures and modelling the remainder as stochastic field. With reference to a typical Large-Eddy Simulation (LES), practical SRS methods seek to resolve a considerably narrower range of scales (physical resolution) to achieve an adequate degree of accuracy at reasonable computational effort. The success of SRS methods depends upon three important factors: $i)$ ability to identify key flow mechanisms responsible for the generation of coherent structures; $ii)$ determine the {optimum range of resolution} required to adequately capture key elements of coherent structures; and $iii)$ ensure that the modelled part is comprised nearly exclusively of fully-developed stochastic turbulence. This study considers the canonical case of the flow around a circular cylinder to address the aforementioned three key issues. It is first demonstrated using experimental evidence that the vortex-shedding instability and flow-structure development involves four important stages. The inherent limitations of the Reynolds-Averaged Navier-Stokes (RANS) approach in addressing the flow physics in these four stages of development are explained. A series of SRS computations of progressively increasing resolution (decreasing cut-off length) are performed. An {\em a priori} basis for locating the origin of the coherent structures development is proposed and examined. The criterion is based on the fact that the coherent structures are generated by the Kelvin-Helmholtz (KH) instability. The most important finding is that the key aspects of coherent structures can be resolved only if the effective computational Reynolds number (based on total viscosity) exceeds the critical value of the KH instability in laminar flows. Finally, a quantitative criterion assessing the nature of the unresolved field based on the strain-rate ratio of mean and unresolved fields is examined. Based on the findings, quantitative guidelines for determining the optimal degree of physical resolution in flows of practical interest are proposed. "
1801_03273_Ti2MnAl.tex," % Weyl semimetals (WSMs) are a new topological state in % condensed matter physics exhibited by systems with broken inversion or % time reversal symmetry. Weyl points in the latter situation can generate % strong anomalous Hall effect (AHE). A special case in time reversal symmetry % breaking system is the compensated magnets, where the net magnetic moment % is zero. Hence, WSM with compensated magnetic structure offers an ideal candidate % to obtain strong AHE without net magnetic moment. We predict a magnetic Weyl semimetal in the inverse Heusler Ti $_2$ MnAl, a compensated ferrimagnet with a vanishing net magnetic moment and a Curie temperature of over 650 K. Despite the vanishing net magnetic moment, we calculate a large intrinsic anomalous Hall effect (AHE) of about 300 S/cm. It derives from the Berry curvature distribution of the Weyl points, which are only 14 meV away from the Fermi level and isolated from trivial bands. Different from antiferromagnets Mn $_3X$ ( $X$ = Ge, Sn, Ga, Ir, Rh, and Pt), where the AHE originates from the non-collinear magnetic structure, the AHE in Ti $_2$ MnAl stems directly from the Weyl points and is topologically  protected. The large anomalous Hall conductivity (AHC) together with a low charge carrier concentration should give rise to a large anomalous Hall angle. In contrast to the Co-based ferromagnetic  Heusler compounds, the Weyl nodes in Ti $_2$ MnAl do not derive from nodal lines due to the lack of mirror symmetries in the inverse Heusler structure. Since the magnetic structure breaks spin-rotation symmetry, the Weyl nodes are stable without SOC. Moreover, because of the large separation between Weyl points of opposite topological charge, the Fermi arcs extent up to $75\%$ of the reciprocal lattice vectors in length. This makes Ti $_2$ MnAl an excellent candidate for the comprehensive study of magnetic Weyl semimetals. It is the first example of a material with Weyl points, large anomalous Hall effect and angle despite a vanishing net magnetic moment. "
1801_01365_springer_chapter_protein_patterns.tex," Protein pattern formation is essential for the spatial organization of many intracellular processes like cell division, flagellum positioning, and chemotaxis. A prominent example of intracellular patterns are the oscillatory pole-to-pole oscillations of Min proteins in E. coli whose biological function is to ensure precise cell division. Cell polarization, a prerequisite for processes such as stem cell differentiation and cell polarity in yeast, is also mediated by a diffusion-reaction process. More generally, these functional modules of cells serve as model systems for self-organization, one of the core principles of life. Under which conditions spatio-temporal patterns emerge, and how these patterns are regulated by biochemical and geometrical factors are major aspects of current research. Here we review recent theoretical and experimental advances in the field of intracellular pattern formation, focusing on general design principles and fundamental physical mechanisms.	 "
1801_02302_00_uavgame.tex," To be successful in multi-player drone racing, a player must not only follow the race track in an optimal way, but also compete with other drones through strategic blocking, faking, and opportunistic passing while avoiding collisions. Since unveiling one's own strategy to the adversaries is not desirable, this requires each player to independently predict the other players' future actions. Nash equilibria are a powerful tool to model this and similar multi-agent coordination problems in which the absence of communication impedes full coordination between the agents. In this paper, we propose a novel receding horizon planning algorithm that, exploiting sensitivity analysis within an iterated best response computational scheme, can approximate Nash equilibria in real time. We also describe a vision-based pipeline that allows each player to estimate its opponent's relative position. We demonstrate that our solution effectively competes against alternative strategies in a large number of drone racing simulations. Hardware experiments with onboard vision sensing prove the practicality of our strategy. "
1801_07478_quatMult-source.tex," Over the last decades quaternions have become a crucial and very successful tool for attitude representation in robotics and aerospace. However, there is a major problem that is continuously causing trouble in practice when it comes to exchanging formulas or implementations: there are two quaternion multiplications in common use, Hamilton's multiplication and its flipped version, which is often associated with NASA's Jet Propulsion Laboratory. We believe that this particular issue is completely avoidable and only exists today due to a lack of understanding. This paper explains the underlying problem for the popular passive world to body usage of rotation quaternions, and derives an alternative solution compatible with Hamilton's multiplication. Furthermore, it argues for entirely discontinuing the flipped multiplication. Additionally, it provides recipes for efficiently detecting relevant conventions and migrating formulas or algorithms between them. "
1801_06538_abstract.tex,"abstract Infrared dark clouds (IRDCs) are thought to be potential hosts of the elusive early phases of high-mass star formation. Here we conduct an in-depth kinematic analysis of one such IRDC, G034.43+00.24 (Cloud F), using high sensitivity and high spectral resolution IRAM-30m \ntwohoz \ and \ceooz \ observations. To disentangle the complex velocity structure within this cloud we use Gaussian decomposition and hierarchical clustering algorithms. We find that four distinct coherent velocity components are present within Cloud F. The properties of these components are compared to those found in a similar IRDC, G035.39-00.33 (Cloud H). We find that the components in both clouds have: high densities (inferred by their identification in \ntwoh), trans-to-supersonic non-thermal velocity dispersions with Mach numbers of $\sim$ \, $1.5-4$ , a separation in velocity of $\sim$ \,3 \kms, and a mean red-shift of $\sim$ \,0.3 \, \kms \ between the \ntwoh \ (dense gas) and \ceo \ emission (envelope gas). The latter of these could suggest that these clouds share a common formation scenario. We investigate the kinematics of the larger-scale Cloud F structures, using lower-density-tracing \tcooz \ observations. A good correspondence is found between the components identified in the IRAM-30m observations and the most prominent component in the \tco \ data. We find that the IRDC Cloud F is only a small part of a much larger structure, which appears to be an inter-arm filament of the Milky Way. "
1801_09513_sept_geant4_paper.tex," The Solar Electron and Proton Telescope (SEPT) aboard the Solar Terrestrial Relations Observatory (STEREO) is designed to provide the three-dimensional distribution of energetic electrons and protons with good energy and time resolution. Each SEPT instrument consists of two double-ended magnet/foil particle telescopes which cleanly separate and measure electrons in the energy range from 30~keV to 400~keV and protons from 60~keV to 7000~keV. Anisotropy information on a non spinning spacecraft is provided by two separate but identical instruments: SEPT-E aligned along the Parker spiral magnetic field in the ecliptic plane along looking both towards and away from the Sun, and SEPT-NS aligned vertical to the ecliptic plane looking towards North and South. The dual set-up refers to two adjacent sensor apertures for each of the four viewing directions SUN, ANTISUN, NORTH, and SOUTH: one for protons, one for electrons. In this contribution a simulation of SEPT utilizing the GEANT4 toolkit has been set up with an extended instrument model in order to calculate improved response functions of the four different telescopes. This will help to understand and correct instrumental effects in the measurements. "
1801_07695_journal_v4.tex," Building on recent development by Padakandla and Pradhan, and by Lim, Feng, Pastore, Nazer, and Gastpar, this paper studies the potential of structured nested coset coding as a complete replacement for random coding in network information theory. The roles of two techniques used in nested coset coding to generate nonuniform codewords, namely, shaping and channel transformation, are clarified and illustrated via the simple example of the two-sender multiple access channel. While individually deficient, the optimal combination of shaping and channel transformation is shown to achieve the same performance as traditional random codes for the general two-sender multiple access channel. The achievability proof of the capacity region is extended to the multiple access channels with more than two senders, and with one or more receivers. A quantization argument consistent with the construction of nested coset codes is presented to prove achievability for their Gaussian counterparts. These results open up new possibilities of utilizing nested coset codes with the same generator matrix for a broader class of applications. "
1801_10124.tex," \noindent I give a simple construction of certain Coulomb branches  $3,4(G;E)$ of gauge theory in $3$ and $4$ dimensions defined by Nakajima et al.  n, bfn for a compact Lie group $G$ and a polarisable quaternionic representation $E$ . The manifolds $0)$  are abelian group schemes (over the bases of regular adjoint $G_\bC$ -orbits, respectively conjugacy classes), and $\cC(G;E)$ is glued together from two copies of $0)$ shifted by a rational Lagrangian section $\vep_V$ , the Euler class of the index bundle of a polarisation $V$ of $E$ . Extending the interpretation of $0)$ as ``classifying space'' for topological $2$ D gauge theories, I characterise functions on $\cC_3(G;E)$ as operators on the equivariant quantum cohomologies of $M\times V$ , for all compact symplectic $G$ -manifolds $M$ . The non-commutative version has a similar description in terms of the $\Gamma$ -function of $V$ , appearing to play the role of Fourier transformed $J$ -function of the gauged linear Sigma-model $V/G$ . "
1801_03148_manuscript.tex," Within the framework of the extended Nambu -- Jona-Lasinio model, we calculate the matrix element of the $- \tau$ decay, obtain the invariant mass distribution of the $f_1\pi$ -system and estimate the branching ratio Br $(-\tau)=4.0-4$ . The two types of contributions are considered: the contact interaction, and the axial-vector $I^G(J^{PC})=1^-(1^{++})$ resonance exchange. The latter includes the ground $a_1(1260)$ state, and its first radially excited state, $a_1(1640)$ . The corrections caused by the $\pi a_1$ transitions are taken into account. Our estimate is in a good agreement with the latest empirical result Br $(- \tau)=(3.9-4$ . The distribution function obtained for the decay $- \tau$ shows a clear signal of $a_1(1640)$ resonance which should be compared with future experimental data. "
1801_03908.tex," A pseudo-length function defined on an arbitrary group $G = (G,\cdot,e, (-1)$ is a map $\normsymb: G \to [0,+\infty)$ obeying $e=0$ , the symmetry property $x^{-1} = x$ , and the triangle inequality $xy x + y$ for all $x,y \in G$ . We consider pseudo-length functions which saturate the triangle inequality whenever $x=y$ , or equivalently those that are homogeneous in the sense that $x^n = nx$ for all $n\in\N$ . We show that this implies that $[x,y]=0$ for all $x,y \in G$ . This leads to a classification of such pseudo-length functions as pullbacks from embeddings into a Banach space. We also obtain a quantitative version of our main result which allows for defects in the triangle inequality or the homogeneity property. "
1801_04124_plszfup.tex,"  We report on the search for optical counterparts of {\planck}  Sunyaev-Zel'dovich (SZ) cluster candidates using a $0.6\,\meter$  non-professional telescope. Among the observed sources, an  unconfirmed candidate, {\aapeVa} , is found to be associated with a  region of more than $100$ galaxies within a $3$ arcminutes  radius around the Sunyaev-Zel'dovich maximum signal  coordinates. From $14$ hours of cumulated exposure over the Sloan  colour filters $g'$ , $r'$ , $i'$ , $z'$ , we estimate the photometric  redshift of these galaxies at $\zphot=0.29 \pm 0.08$ . Combined with  the {\planck} SZ proxy mass function, this would favour a cluster of  $4.4 14$ solar masses. This result suggests that   a dedicated pool of observatories equipped with such   instruments could collectively contribute to optical follow-up   programs of massive cluster candidates at moderate redshifts. "
1801_03582_manuscript_02.tex," Recently,  Belle Collaboration has  reported the measurement  of the spin-flipping  transition $\Upsilon(4S) \to h_b(1P)\eta$ with an unexpectedly large branching ratio:  $B(-3$ . Such a large branching fraction contradicts with the anticipated  suppression for the spin flip. In this work, we examine the effects induced by intermediate bottomed meson loops and point out that these effects are significantly important. Using the effective Lagrangian approach (ELA), we find the experimental data on $\Upsilon(4S) \to h_b(1P)\eta$ can be accommodated with the reasonable inputs. We then explore the decays $\Upsilon(5S,6S)\to h_b(1P)\eta$  and find that these two channels also have sizable branching fractions. We also calculate these these processes in the framework of nonrelativistic effective field theory (NREFT). For the decays $\Upsilon(4S) \to h_b(1P) \eta$ , the NREFT results are at the same order of magnitude but smaller than the ELA results by a factor of $2$ to $5$ . For the decays $\Upsilon(5S, 6S) \to h_b(1P) \eta$  the NREFT results are smaller than the ELA results by approximately one order of magnitude. We suggest future experiment Belle-II to search for the $\Upsilon(5S, 6S)\to h_b(1P) \eta$ decays which will be helpful to understand  the transition mechanism. "
1801_01465_QImg.tex," Processing of digital images is continuously gaining in volume and relevance, with concomitant demands on data storage, transmission and processing power. Encoding the image information in quantum-mechanical systems instead of classical ones and replacing classical with quantum information processing may alleviate some of these challenges. By encoding and processing the image information in quantum-mechanical systems, we here demonstrate the framework of quantum image processing, where a pure quantum state encodes the image information: we encode the pixel values in the probability amplitudes and the pixel positions in the computational basis states. Our quantum image representation reduces the required number of qubits compared to existing implementations, and we present image processing algorithms that provide exponential speed-up over their classical counterparts. For the commonly used task of detecting the edge of an image, we propose and implement a quantum algorithm that completes the task with only one single-qubit operation, independent of the size of the image. This demonstrates the potential of quantum image processing for highly efficient image and video processing in the big data era. "
1801_01766.tex," In this paper, we give two new coding algorithms by means of right circulant matrices with elements generalized Fibonacci and Lucas polynomials. For this purpose, we study basic properties of right circulant matrices using generalized Fibonacci polynomials $F_{p,q,n}\left( x\right) $ , generalized Lucas polynomials $L_{p,q,n}\left( x\right) $ and geometric sequences. "
1801_01315_pixel_link.tex," 		Most state-of-the-art scene text detection algorithms are deep learning based methods that depend on bounding box regression and perform at least two kinds of predictions: text/non-text classification and location regression. Regression plays a key role in the acquisition of bounding boxes in these methods, but it is not indispensable because text/non-text prediction can also be considered as a kind of semantic segmentation that contains full location information in itself. However, text instances in scene images often lie very close to each other, making them very difficult to separate via semantic segmentation. Therefore, instance segmentation is needed to address this problem. In this paper, PixelLink, aƒ novel scene text detection algorithm based on instance segmentation, is proposed. Text instances are first segmented out by linking pixels within the same instance together. Text bounding boxes are then extracted directly from the segmentation result without location regression. Experiments show that, compared with regression-based methods, PixelLink can achieve better or comparable performance on several benchmarks, while requiring many fewer training iterations and less training data. 	"
1801_02704_mpm8.tex,"  Models of hadronization of hard jets in QCD are often presented in  terms of Feynman-graph structures that can be thought of as  effective field theory approximations to dynamical non-perturbative  physics in QCD. Such models can be formulated as a kind of  multiperipheral model. We obtain general constraints on such models  in order for them to be self-consistent, and we relate the  constraints to the space-time structure of hadronization. We show  that appropriate models can be considered as implementing  string-like hadronization. When the models are put in a  multiperipheral form, the effective vertices and/or lines must be  momentum non-conserving: they take 4-momentum from the external  string-like field. "
1801_02628_CDTC_main.tex," % The spontaneous breaking of time-translation symmetry in periodically driven quantum systems leads to a new phase of matter: discrete time crystals (DTC). This phase exhibits collective subharmonic oscillations that depend upon an interplay of non-equilibrium driving, many-body interactions, and the breakdown of ergodicity. % However, subharmonic responses van1927frequency are also a well-known feature of classical dynamical systems ranging from predator-prey models may1976simple to Faraday waves CrossHohenberg and AC-driven charge density waves Brown1984 . This raises the question of whether these classical phenomena display the same rigidity characteristic of a quantum DTC. In this work, we explore this question in the context of periodically driven Hamiltonian dynamics coupled to a finite-temperature bath, which provides both friction and, crucially, noise. Focusing on one-dimensional chains, where in equilibrium any transition would be forbidden at finite temperature, we provide evidence that the combination of noise and interactions drives a sharp, first-order dynamical phase transition between a discrete time-translation invariant phase and an activated classical discrete time crystal (CDTC) in which time-translation symmetry is broken out to exponentially-long time scales. Power-law correlations are present along a first-order line which terminates at a critical point. We analyze the transition by mapping it to the locked-to-sliding transition of a DC-driven charge density wave. Our work points to a classical limit for quantum time crystals, and raises several intriguing questions concerning the non-equilibrium universality class of the CDTC critical point. "
1801_01615_tbc_cvpr.tex," We present a unified deformation model for the markerless capture of multiple scales of human movement, including facial expressions, body motion, and hand gestures. An initial model is generated by locally stitching together models of the individual parts of the human body, which we refer to as the ``Frankenstein'' model. This model enables the full expression of part movements, including face and hands by a single seamless model. Using a large-scale capture of people wearing everyday clothes, we optimize the Frankenstein model to create ``Adam"". Adam is a calibrated model that shares the same skeleton hierarchy as the initial model but can express hair and clothing geometry, making it directly usable for fitting people as they normally appear in everyday life. Finally, we demonstrate the use of these models for total motion tracking, simultaneously capturing the large-scale body movements and the subtle face and hand motion of a social group of people. %  We present a method to capture the ``total body motion'' of multiple people, including their 3D body motion, facial expression, and hand gestures. Our method has three main contributions: 1) we present a method to build a novel human body template model, named ``Frankenstein'', by leveraging existing part models. This approach enables the full expression of multi-scale part movements, including face and hands as a unified, seamless model; 2) We produce a new PCA-based blendshape model for total motion capture, named ``Adam"". The model shares the same skeleton hierarchy as the Frankenstein model, but is simpler to use and better models hair and clothing geometry; and 3) We present a total motion tracking method based on these models, and demonstrate unprecedented markerless motion tracking results with subtle details on a variety of challenging sequences. "
abstract.tex," Neural programming involves training neural networks to learn programs from data. Previous works have failed to achieve good generalization performance, especially on programs with high complexity or on large domains. This is because they mostly rely either on black-box function evaluations that do not capture the structure of the program, or on detailed execution traces that are expensive to obtain, and hence the training data has poor coverage of the domain under consideration. We present a novel framework that utilizes black-box function evaluations, in conjunction with symbolic expressions that integrate relationships between the given functions. We employ tree LSTMs to incorporate the structure of the symbolic expression trees.  %as well as numeric expression trees for function evaluation data but doesn't numeric expression tree be identical to the corresponding symbolic expression tree for a given equation? no need to explicitly mention it  We use tree encoding for numbers present in function evaluation data, based on their decimal representation. We present an evaluation benchmark for this task to demonstrate our proposed model combines symbolic reasoning and function evaluation in a fruitful manner, obtaining high accuracies in our experiments. %We show state of art performance on the application of mathematical equation modeling. Our framework generalizes significantly better to expressions of higher depth and is able to fill partial equations with valid completions. %The state-of-the-art methods for neural symbolic reasoning either rely solely on input-output data or rely entirely on symbolic representation of expressions for training. We propose, for the first time, combining input-output or numeric data with symbolic expressions for neural symbolic reasoning. Input-output data enables function evaluation, however, it is not scalable and it results in models that lack generalization ability. Symbolic representations provide a compact representation of the problem and are therefore, more scalable and result in more generalizable models. However, they are not capable of function evaluation. Our combinatorial approach takes advantage of the benefits of both strategies, resulting in generalizable and scalable models capable of function evaluation. We apply our proposed method to the problem of modeling mathematical equations. We change the state-of-the-art formulation of this problem to broaden its applicability from equation simplification to equation completion. We also propose a symbolic and numeric dataset generation strategy that results in a balanced dataset with a good coverage of the mathematical domain under study. Our experiments show that training Tree LSTM's on a combination of numeric and symbolic data results in models capable of more complex reasoning with less data. % %Our dataset generation is applicable to any domain in mathematics by providing to it as input, the main axioms of the desired domain. %; it provides scalability and generalizability while enabling function evaluation %a recent domain in neural symbolic reasoning, which is % Input-output data methods are in general not scalable and lack generalizability. Therefore, we should use symbolic representations efficiently to learn generalizable models. However, Approaching the problem in a completely symbolic manner, does not allow function evaluation. Therefore, in order to enable function evaluation while achieving generalizability and efficiency, we  % Input-output data enables function evaluation, however, it is not scalable and lacks generalizability. Symbolic representations provide a compact representation of the problem and therefore, result in more generalizable models. and enable approaching problems in a completely symbolic manner. But from a training perspective, these symbolic representations are too compact . Moreover, we cannot perform function evaluation. We propose combining symbolic expressions with input-output data or function evaluation that leverages the benefits of both strategies. We show that combining input-output data and symbolic representations results in more generalizable models that achieve superior performance compared to either method. This results in symbolic models that are capable of function evaluation. We apply our proposed method to a recent domain in neural symbolic reasoning, which is modeling mathematical equations. We change the state-of-the-art formulation of the problem to broaden their applicability from equation simplification to identity completion. We also propose a dataset generation strategy that results in a balanced dataset with a good coverage of the mathematical domain under study. Our dataset generation is applicable to any domain in mathematics by providing to it as input, the main axioms of the desired domain. %In this paper, we propose combining symbolic axioms and theorems with input-output data for neural symbolic reasoning. We introduce a novel framework for symbolic reasoning over mathematical identities that is applicable to tasks such as predicting the correctness of mathematical equations and equation completion. We show that combining input-output data with symbolic equations is crucial to the generalization performance of the model. This model can be used for novel tasks of predicting the correctness of identities as well as identity completion. Each mathematical function is assigned a neural network cell that is responsible for memorizing its properties. The neural network cell is shared among all occurrences of the function in various identities. Embedded vectors at the output of each cell are propagated along the tree structure given by the mathematical identity to the root of the tree were correctness of the identity is predicted. We deploy this framework on identities in trigonometry and elementary algebra as a case study. We establish that the combination of input-output data as well as the structure of the neural network gives the best performance on various tasks such as prediction of equation correctness and identity completion. %In this paper, we model mathematical identities from symbolic axioms and theorems. We propose a neural trigonometer that uses recursive Long Short-Term Memory (LSTM) to learn the properties of the underlying functions in mathematics. The neural trigonometer consists of a recursive LSTM network that mirrors the compositional tree structure of the input equation. Instead of using input-output data to the neural trigonometer, we feed in the relevant mathematical axioms and identities. Each mathematical function is assigned an LSTM cell that is responsible for memorizing its properties. This information is propagated along the tree structure given by the mathematical identity. The LSTM cell is shared among all occurrences of the function in various identities. We deploy this framework on identities in trigonometry and elementary algebra as a case study. We establish that the combination of the memory of an LSTM cell and the structure of the recursive network gives the best performance on the equation completion task.  % We aim at learning the properties of the underlying functions in trigonometry and elementary algebra by feeding correct and incorrect symbolic expression to our model.  % The neural network consists of a recursive Long Short-Term Memory (LSTM) network whose structure is indicated by the structure of the input equation. We use a large number of correct and incorrect algebraic and trigonometric equations to learn the properties of trigonometric and elementary algebraic functions such as the commutative/associative/distributive properties of addition or the properties of the sine function. Therefore, we are leveraging the basic algebraic and trigonometric axioms as well as the structure of equations to learn trigonometry and elementary algebra. The main novelty of this work is that none of the state-of-the-art neural programmers have aimed at learning the properties of all trigonometric and elementary functions from symbolic equations and they have rather focused on learning about single or a limited number of mathematical functions. For example, researchers have aimed at learning addition by using numeric input-output data which ignores the main properties of the addition function. "
paper_current_material.tex," We consider the problem of envy-free cake cutting, which is the distribution of a continuous heterogeneous resource among self interested players such that nobody prefers what somebody else receives to what they get. Existing work has focused on two distinct classes of solutions to this problem - allocations which give each player a continuous piece of cake and allocations which give each player arbitrarily many disjoint pieces of cake. Our aim is to investigate allocations between these two extremes by parameterizing the maximum number of disjoint pieces each player may receive. We characterize the Price of Indivisibility (POI) as the gain achieved in social welfare (utilitarian and egalitarian), by moving from allocations which give each player a continuous piece of cake to allocations that may give each player up to $k$ disjoint pieces of cake. Our results contain bounds for the Price of Indivisibility for utilitarian as well as egalitarian social welfare, and for envy-free cake cutting as well as cake cutting without any fairness constraints. "
defending_CSRF_0123.tex," Many millions of users routinely use their Google, Facebook and Microsoft accounts to log in to websites supporting OAuth 2.0 and/or OpenID Connect-based single sign on. The security of OAuth 2.0 and OpenID Connect is therefore of critical importance, and it has been widely examined both in theory and in practice. Unfortunately, as these studies have shown, real-world implementations of both schemes are often vulnerable to attack, and in particular to cross-site request forgery (CSRF) attacks. In this paper we propose a new technique which can be used to mitigate CSRF attacks against both OAuth 2.0 and OpenID Connect. %RURIM attacks are related to the IdP mix-up attacks of Fett et al.  %We reported our findings to the affected 23 identity providers and helped them fix the problem. "
sigproc-sp.tex," This paper provides a sample of a \LaTeX \ document which conforms to the formatting guidelines for ACM SIG Proceedings. It complements the document \textit{Author's Guide to Preparing ACM SIG Proceedings Using \LaTeX $2_\epsilon$\ and Bib\TeX} . This source file has been written with the intention of being compiled under \LaTeX $2_\epsilon$ \ and BibTeX. The developers have tried to include every imaginable sort of ``bells and whistles"", such as a subtitle, footnotes on title, subtitle and authors, as well as in the text, and every optional component (e.g. Acknowledgments, Additional Authors, Appendices), not to mention examples of equations, theorems, tables and figures. To make best use of this sample document, run it through \LaTeX \ and BibTeX, and compare this source code with the printed output produced by the dvi file. "
